<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.36">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Hansen中高级计量体系 - 9&nbsp; Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chpt10-resample-method.html" rel="next">
<link href="./chpt08-restricted-est.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hansen中高级计量体系</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/huhuaping/hansenEM/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">前言</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./participate.html" class="sidebar-item-text sidebar-link">如何参与？</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt01-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part01-reg.html" class="sidebar-item-text sidebar-link">回归</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt02-ce.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Conditional Expectation and Projection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt03-algebra.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Algebra of Least Squares</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt04-lsr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Least Squares Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt05-normal-reg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Normal Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part02-LSM.html" class="sidebar-item-text sidebar-link">大样本方法</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt06-review.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A Review of Large Sample Asymptotics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt07-asymptotic-ls.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Asymptotic Theory for Least Squares</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt08-restricted-est.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Restricted Estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt09-hypothesit-test.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt10-resample-method.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Resampling Methods</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part03-MEQ.html" class="sidebar-item-text sidebar-link">多方程模型</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt11-multi-reg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Multivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt12-iv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Instrumental Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chpt13-gmm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Generalized Method of Moments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">Summary</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Appendices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a1-notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">附录a1</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#hypotheses" id="toc-hypotheses" class="nav-link active" data-scroll-target="#hypotheses"> <span class="header-section-number">9.1</span> Hypotheses</a></li>
  <li><a href="#acceptance-and-rejection" id="toc-acceptance-and-rejection" class="nav-link" data-scroll-target="#acceptance-and-rejection"> <span class="header-section-number">9.2</span> Acceptance and Rejection</a></li>
  <li><a href="#type-i-error" id="toc-type-i-error" class="nav-link" data-scroll-target="#type-i-error"> <span class="header-section-number">9.3</span> Type I Error</a></li>
  <li><a href="#t-tests" id="toc-t-tests" class="nav-link" data-scroll-target="#t-tests"> <span class="header-section-number">9.4</span> t tests</a></li>
  <li><a href="#type-ii-error-and-power" id="toc-type-ii-error-and-power" class="nav-link" data-scroll-target="#type-ii-error-and-power"> <span class="header-section-number">9.5</span> Type II Error and Power</a></li>
  <li><a href="#statistical-significance" id="toc-statistical-significance" class="nav-link" data-scroll-target="#statistical-significance"> <span class="header-section-number">9.6</span> Statistical Significance</a></li>
  <li><a href="#p-values" id="toc-p-values" class="nav-link" data-scroll-target="#p-values"> <span class="header-section-number">9.7</span> P-Values</a></li>
  <li><a href="#t-ratios-and-the-abuse-of-testing" id="toc-t-ratios-and-the-abuse-of-testing" class="nav-link" data-scroll-target="#t-ratios-and-the-abuse-of-testing"> <span class="header-section-number">9.8</span> t-ratios and the Abuse of Testing</a></li>
  <li><a href="#wald-tests" id="toc-wald-tests" class="nav-link" data-scroll-target="#wald-tests"> <span class="header-section-number">9.9</span> Wald Tests</a></li>
  <li><a href="#homoskedastic-wald-tests" id="toc-homoskedastic-wald-tests" class="nav-link" data-scroll-target="#homoskedastic-wald-tests"> <span class="header-section-number">9.10</span> Homoskedastic Wald Tests</a></li>
  <li><a href="#criterion-based-tests" id="toc-criterion-based-tests" class="nav-link" data-scroll-target="#criterion-based-tests"> <span class="header-section-number">9.11</span> Criterion-Based Tests</a></li>
  <li><a href="#minimum-distance-tests" id="toc-minimum-distance-tests" class="nav-link" data-scroll-target="#minimum-distance-tests"> <span class="header-section-number">9.12</span> Minimum Distance Tests</a></li>
  <li><a href="#minimum-distance-tests-under-homoskedasticity" id="toc-minimum-distance-tests-under-homoskedasticity" class="nav-link" data-scroll-target="#minimum-distance-tests-under-homoskedasticity"> <span class="header-section-number">9.13</span> Minimum Distance Tests Under Homoskedasticity</a></li>
  <li><a href="#f-tests" id="toc-f-tests" class="nav-link" data-scroll-target="#f-tests"> <span class="header-section-number">9.14</span> F Tests</a></li>
  <li><a href="#hausman-tests" id="toc-hausman-tests" class="nav-link" data-scroll-target="#hausman-tests"> <span class="header-section-number">9.15</span> Hausman Tests</a></li>
  <li><a href="#score-tests" id="toc-score-tests" class="nav-link" data-scroll-target="#score-tests"> <span class="header-section-number">9.16</span> Score Tests</a></li>
  <li><a href="#problems-with-tests-of-nonlinear-hypotheses" id="toc-problems-with-tests-of-nonlinear-hypotheses" class="nav-link" data-scroll-target="#problems-with-tests-of-nonlinear-hypotheses"> <span class="header-section-number">9.17</span> Problems with Tests of Nonlinear Hypotheses</a></li>
  <li><a href="#monte-carlo-simulation" id="toc-monte-carlo-simulation" class="nav-link" data-scroll-target="#monte-carlo-simulation"> <span class="header-section-number">9.18</span> Monte Carlo Simulation</a></li>
  <li><a href="#confidence-intervals-by-test-inversion" id="toc-confidence-intervals-by-test-inversion" class="nav-link" data-scroll-target="#confidence-intervals-by-test-inversion"> <span class="header-section-number">9.19</span> Confidence Intervals by Test Inversion</a></li>
  <li><a href="#multiple-tests-and-bonferroni-corrections" id="toc-multiple-tests-and-bonferroni-corrections" class="nav-link" data-scroll-target="#multiple-tests-and-bonferroni-corrections"> <span class="header-section-number">9.20</span> Multiple Tests and Bonferroni Corrections</a></li>
  <li><a href="#power-and-test-consistency" id="toc-power-and-test-consistency" class="nav-link" data-scroll-target="#power-and-test-consistency"> <span class="header-section-number">9.21</span> Power and Test Consistency</a></li>
  <li><a href="#asymptotic-local-power" id="toc-asymptotic-local-power" class="nav-link" data-scroll-target="#asymptotic-local-power"> <span class="header-section-number">9.22</span> Asymptotic Local Power</a></li>
  <li><a href="#asymptotic-local-power-vector-case" id="toc-asymptotic-local-power-vector-case" class="nav-link" data-scroll-target="#asymptotic-local-power-vector-case"> <span class="header-section-number">9.23</span> Asymptotic Local Power, Vector Case</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"> <span class="header-section-number">9.24</span> Exercises</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/huhuaping/hansenEM/edit/master/chpt09-hypothesit-test.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In Chapter 5 we briefly introduced hypothesis testing in the context of the normal regression model. In this chapter we explore hypothesis testing in greater detail with a particular emphasis on asymptotic inference. For more detail on the foundations see Chapter 13 of Probability and Statistics for Economists.</p>
<section id="hypotheses" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="hypotheses"><span class="header-section-number">9.1</span> Hypotheses</h2>
<p>In Chapter 8 we discussed estimation subject to restrictions, including linear restrictions (8.1), nonlinear restrictions (8.44), and inequality restrictions (8.49). In this chapter we discuss tests of such restrictions.</p>
<p>Hypothesis tests attempt to assess whether there is evidence contrary to a proposed restriction. Let <span class="math inline">\(\theta=r(\beta)\)</span> be a <span class="math inline">\(q \times 1\)</span> parameter of interest where <span class="math inline">\(r: \mathbb{R}^{k} \rightarrow \Theta \subset \mathbb{R}^{q}\)</span> is some transformation. For example, <span class="math inline">\(\theta\)</span> may be a single coefficient, e.g.&nbsp;<span class="math inline">\(\theta=\beta_{j}\)</span>, the difference between two coefficients, e.g.&nbsp;<span class="math inline">\(\theta=\beta_{j}-\beta_{\ell}\)</span>, or the ratio of two coefficients, e.g.&nbsp;<span class="math inline">\(\theta=\beta_{j} / \beta_{\ell}\)</span>.</p>
<p>A point hypothesis concerning <span class="math inline">\(\theta\)</span> is a proposed restriction such as</p>
<p><span class="math display">\[
\theta=\theta_{0}
\]</span></p>
<p>where <span class="math inline">\(\theta_{0}\)</span> is a hypothesized (known) value.</p>
<p>More generally, letting <span class="math inline">\(\beta \in B \subset \mathbb{R}^{k}\)</span> be the parameter space, a hypothesis is a restriction <span class="math inline">\(\beta \in B_{0}\)</span> where <span class="math inline">\(B_{0}\)</span> is a proper subset of <span class="math inline">\(B\)</span>. This specializes to (9.1) by setting <span class="math inline">\(B_{0}=\left\{\beta \in B: r(\beta)=\theta_{0}\right\}\)</span>.</p>
<p>In this chapter we will focus exclusively on point hypotheses of the form (9.1) as they are the most common and relatively simple to handle.</p>
<p>The hypothesis to be tested is called the null hypothesis.</p>
<p>Definition 9.1 The null hypothesis <span class="math inline">\(\mathbb{M}_{0}\)</span> is the restriction <span class="math inline">\(\theta=\theta_{0}\)</span> or <span class="math inline">\(\beta \in B_{0}\)</span>.</p>
<p>We often write the null hypothesis as <span class="math inline">\(\mathbb{M}_{0}: \theta=\theta_{0}\)</span> or <span class="math inline">\(\mathbb{M}_{0}: r(\beta)=\theta_{0}\)</span>.</p>
<p>The complement of the null hypothesis (the collection of parameter values which do not satisfy the null hypothesis) is called the alternative hypothesis.</p>
<p>Definition 9.2 The alternative hypothesis <span class="math inline">\(\mathbb{M}_{1}\)</span> is the set <span class="math inline">\(\left\{\theta \in \Theta: \theta \neq \theta_{0}\right\}\)</span> or <span class="math inline">\(\left\{\beta \in B: \beta \notin B_{0}\right\}\)</span> We often write the alternative hypothesis as <span class="math inline">\(\mathbb{M}_{1}: \theta \neq \theta_{0}\)</span> or <span class="math inline">\(\mathbb{M}_{1}: r(\beta) \neq \theta_{0}\)</span>. For simplicity, we often refer to the hypotheses as “the null” and “the alternative”. Figure 9.1(a) illustrates the division of the parameter space into null and alternative hypotheses.</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-02.jpg" class="img-fluid"></p>
<ol type="a">
<li>Null and Alternative Hypotheses</li>
</ol>
<p><img src="images//2022_09_17_d22774979aa7978900adg-02(1).jpg" class="img-fluid"></p>
<ol start="2" type="a">
<li>Acceptance and Rejection Regions</li>
</ol>
<p>Figure 9.1: Hypothesis Testing</p>
<p>In hypothesis testing, we assume that there is a true (but unknown) value of <span class="math inline">\(\theta\)</span> and this value either satisfies <span class="math inline">\(\mathbb{M}_{0}\)</span> or does not satisfy <span class="math inline">\(\mathbb{M}_{0}\)</span>. The goal of hypothesis testing is to assess whether or not <span class="math inline">\(\mathbb{H}_{0}\)</span> is true by asking if <span class="math inline">\(\mathbb{M}_{0}\)</span> is consistent with the observed data.</p>
<p>To be specific, take our example of wage determination and consider the question: Does union membership affect wages? We can turn this into a hypothesis test by specifying the null as the restriction that a coefficient on union membership is zero in a wage regression. Consider, for example, the estimates reported in Table 4.1. The coefficient for “Male Union Member” is <span class="math inline">\(0.095\)</span> (a wage premium of <span class="math inline">\(9.5 %\)</span> ) and the coefficient for “Female Union Member” is <span class="math inline">\(0.022\)</span> (a wage premium of <span class="math inline">\(2.2 %\)</span> ). These are estimates, not the true values. The question is: Are the true coefficients zero? To answer this question the testing method asks the question: Are the observed estimates compatible with the hypothesis, in the sense that the deviation from the hypothesis can be reasonably explained by stochastic variation? Or are the observed estimates incompatible with the hypothesis, in the sense that that the observed estimates would be highly unlikely if the hypothesis were true?</p>
</section>
<section id="acceptance-and-rejection" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="acceptance-and-rejection"><span class="header-section-number">9.2</span> Acceptance and Rejection</h2>
<p>A hypothesis test either accepts the null hypothesis or rejects the null hypothesis in favor of the alternative hypothesis. We can describe these two decisions as “Accept <span class="math inline">\(\mathbb{H}_{0}\)</span>” and “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span>”. In the example given in the previous section the decision is either to accept the hypothesis that union membership does not affect wages, or to reject the hypothesis in favor of the alternative that union membership does affect wages.</p>
<p>The decision is based on the data and so is a mapping from the sample space to the decision set. This splits the sample space into two regions <span class="math inline">\(S_{0}\)</span> and <span class="math inline">\(S_{1}\)</span> such that if the observed sample falls into <span class="math inline">\(S_{0}\)</span> we accept <span class="math inline">\(\mathbb{M}_{0}\)</span>, while if the sample falls into <span class="math inline">\(S_{1}\)</span> we reject <span class="math inline">\(\mathbb{M}_{0}\)</span>. The set <span class="math inline">\(S_{0}\)</span> is called the acceptance region and the set <span class="math inline">\(S_{1}\)</span> the rejection or critical region.</p>
<p>It is convenient to express this mapping as a real-valued function called a test statistic</p>
<p><span class="math display">\[
T=T\left(\left(Y_{1}, X_{1}\right), \ldots,\left(Y_{n}, X_{n}\right)\right)
\]</span></p>
<p>relative to a critical value <span class="math inline">\(c\)</span>. The hypothesis test then consists of the decision rule:</p>
<ol type="1">
<li><p>Accept <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(T \leq c\)</span>.</p></li>
<li><p>Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(T&gt;c\)</span>.</p></li>
</ol>
<p>Figure 9.1(b) illustrates the division of the sample space into acceptance and rejection regions.</p>
<p>A test statistic <span class="math inline">\(T\)</span> should be designed so that small values are likely when <span class="math inline">\(\mathbb{H}_{0}\)</span> is true and large values are likely when <span class="math inline">\(\mathbb{M}_{1}\)</span> is true. There is a well developed statistical theory concerning the design of optimal tests. We will not review that theory here, but instead refer the reader to Lehmann and Romano (2005). In this chapter we will summarize the main approaches to the design of test statistics.</p>
<p>The most commonly used test statistic is the absolute value of the t-statistic</p>
<p><span class="math display">\[
T=\left|T\left(\theta_{0}\right)\right|
\]</span></p>
<p>where</p>
<p><span class="math display">\[
T(\theta)=\frac{\widehat{\theta}-\theta}{s(\widehat{\theta})}
\]</span></p>
<p>is the t-statistic from (7.33), <span class="math inline">\(\widehat{\theta}\)</span> is a point estimator, and <span class="math inline">\(s(\widehat{\theta})\)</span> its standard error. <span class="math inline">\(T\)</span> is an appropriate statistic when testing hypotheses on individual coefficients or real-valued parameters <span class="math inline">\(\theta=h(\beta)\)</span> and <span class="math inline">\(\theta_{0}\)</span> is the hypothesized value. Quite typically <span class="math inline">\(\theta_{0}=0\)</span>, as interest focuses on whether or not a coefficient equals zero, but this is not the only possibility. For example, interest may focus on whether an elasticity <span class="math inline">\(\theta\)</span> equals 1 , in which case we may wish to test <span class="math inline">\(\mathbb{H}_{0}: \theta=1\)</span>.</p>
</section>
<section id="type-i-error" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="type-i-error"><span class="header-section-number">9.3</span> Type I Error</h2>
<p>A false rejection of the null hypothesis <span class="math inline">\(\mathbb{H}_{0}\)</span> (rejecting <span class="math inline">\(\mathbb{M}_{0}\)</span> when <span class="math inline">\(\mathbb{H}_{0}\)</span> is true) is called a Type I error. The probability of a Type I error is called the size of the test.</p>
<p><span class="math display">\[
\mathbb{P}\left[\text { Reject } \mathbb{H}_{0} \mid \mathbb{H}_{0} \text { true }\right]=\mathbb{P}\left[T&gt;c \mid \mathbb{H}_{0} \text { true }\right] .
\]</span></p>
<p>The uniform size of the test is the supremum of (9.4) across all data distributions which satisfy <span class="math inline">\(\mathbb{H}_{0}\)</span>. A primary goal of test construction is to limit the incidence of Type I error by bounding the size of the test.</p>
<p>For the reasons discussed in Chapter 7 , in typical econometric models the exact sampling distributions of estimators and test statistics are unknown and hence we cannot explicitly calculate (9.4). Instead, we typically rely on asymptotic approximations. Suppose that the test statistic has an asymptotic distribution under <span class="math inline">\(\mathbb{H}_{0}\)</span>. That is, when <span class="math inline">\(\mathbb{H}_{0}\)</span> is true</p>
<p><span class="math display">\[
T \longrightarrow \underset{d}{\xi}
\]</span></p>
<p>as <span class="math inline">\(n \rightarrow \infty\)</span> for some continuously-distributed random variable <span class="math inline">\(\xi\)</span>. This is not a substantive restriction as most conventional econometric tests satisfy (9.5). Let <span class="math inline">\(G(u)=\mathbb{P}[\xi \leq u]\)</span> denote the distribution of <span class="math inline">\(\xi\)</span>. We call <span class="math inline">\(\xi\)</span> (or <span class="math inline">\(G\)</span> ) the asymptotic null distribution. It is desirable to design test statistics <span class="math inline">\(T\)</span> whose asymptotic null distribution <span class="math inline">\(G\)</span> is known and does not depend on unknown parameters. In this case we say that <span class="math inline">\(T\)</span> is asymptotically pivotal.</p>
<p>For example, if the test statistic equals the absolute <span class="math inline">\(t\)</span>-statistic from (9.2), then we know from Theorem <span class="math inline">\(7.11\)</span> that if <span class="math inline">\(\theta=\theta_{0}\)</span> (that is, the null hypothesis holds), then <span class="math inline">\(T \underset{d}{\rightarrow}|Z|\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> where <span class="math inline">\(Z \sim \mathrm{N}(0,1)\)</span>. This means that <span class="math inline">\(G(u)=\mathbb{P}[|Z| \leq u]=2 \Phi(u)-1\)</span>, the distribution of the absolute value of the standard normal as shown in (7.34). This distribution does not depend on unknowns and is pivotal.</p>
<p>We define the asymptotic size of the test as the asymptotic probability of a Type I error:</p>
<p><span class="math display">\[
\lim _{n \rightarrow \infty} \mathbb{P}\left[T&gt;c \mid \mathbb{M}_{0} \text { true }\right]=\mathbb{P}[\xi&gt;c]=1-G(c) .
\]</span></p>
<p>We see that the asymptotic size of the test is a simple function of the asymptotic null distribution <span class="math inline">\(G\)</span> and the critical value <span class="math inline">\(c\)</span>. For example, the asymptotic size of a test based on the absolute t-statistic with critical value <span class="math inline">\(c\)</span> is <span class="math inline">\(2(1-\Phi(c))\)</span>.</p>
<p>In the dominant approach to hypothesis testing the researcher pre-selects a significance level <span class="math inline">\(\alpha \epsilon\)</span> <span class="math inline">\((0,1)\)</span> and then selects <span class="math inline">\(c\)</span> so the asymptotic size is no larger than <span class="math inline">\(\alpha\)</span>. When the asymptotic null distribution <span class="math inline">\(G\)</span> is pivotal we accomplish this by setting <span class="math inline">\(c\)</span> equal to the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution <span class="math inline">\(G\)</span>. (If the distribution <span class="math inline">\(G\)</span> is not pivotal more complicated methods must be used.) We call <span class="math inline">\(c\)</span> the asymptotic critical value because it has been selected from the asymptotic null distribution. For example, since <span class="math inline">\(2(1-\Phi(1.96))=0.05\)</span> it follows that the <span class="math inline">\(5 %\)</span> asymptotic critical value for the absolute t-statistic is <span class="math inline">\(c=1.96\)</span>. Calculation of normal critical values is done numerically in statistical software. For example, in MATLAB the command is norminv <span class="math inline">\((1-\alpha / 2)\)</span>.</p>
</section>
<section id="t-tests" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="t-tests"><span class="header-section-number">9.4</span> t tests</h2>
<p>As we mentioned earlier, the most common test of the one-dimensional hypothesis <span class="math inline">\(\mathbb{H}_{0}: \theta=\theta_{0} \in \mathbb{R}\)</span> against the alternative <span class="math inline">\(\mathbb{M}_{1}: \theta \neq \theta_{0}\)</span> is the absolute value of the <span class="math inline">\(\mathrm{t}\)</span>-statistic (9.3). We now formally state its asymptotic null distribution, which is a simple application of Theorem 7.11.</p>
<p>Theorem 9.1 Under Assumptions 7.2, 7.3, and <span class="math inline">\(\mathbb{H}_{0}: \theta=\theta_{0} \in \mathbb{R}, T\left(\theta_{0}\right) \underset{d}{\longrightarrow} Z \sim\)</span> <span class="math inline">\(\mathrm{N}(0,1)\)</span>. For <span class="math inline">\(c\)</span> satisfying <span class="math inline">\(\alpha=2(1-\Phi(c)), \mathbb{P}\left[\left|T\left(\theta_{0}\right)\right|&gt;c \mid \mathbb{H}_{0}\right] \rightarrow \alpha\)</span>, and the test “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(\left|T\left(\theta_{0}\right)\right|&gt;c\)</span>” has asymptotic size <span class="math inline">\(\alpha\)</span>.</p>
<p>Theorem 9.1 shows that asymptotic critical values can be taken from the normal distribution. As in our discussion of asymptotic confidence intervals (Section 7.13) the critical value could alternatively be taken from the student <span class="math inline">\(t\)</span> distribution, which would be the exact test in the normal regression model (Section 5.12). Indeed, <span class="math inline">\(t\)</span> critical values are the default in packages such as Stata. Since the critical values from the student <span class="math inline">\(t\)</span> distribution are (slightly) larger than those from the normal distribution, student <span class="math inline">\(t\)</span> critical values slightly decrease the rejection probability of the test. In practical applications the difference is typically unimportant unless the sample size is quite small (in which case the asymptotic approximation should be questioned as well).</p>
<p>The alternative hypothesis <span class="math inline">\(\theta \neq \theta_{0}\)</span> is sometimes called a “two-sided” alternative. In contrast, sometimes we are interested in testing for one-sided alternatives such as <span class="math inline">\(\mathbb{M}_{1}: \theta&gt;\theta_{0}\)</span> or <span class="math inline">\(\mathbb{H}_{1}: \theta&lt;\theta_{0}\)</span>. Tests of <span class="math inline">\(\theta=\theta_{0}\)</span> against <span class="math inline">\(\theta&gt;\theta_{0}\)</span> or <span class="math inline">\(\theta&lt;\theta_{0}\)</span> are based on the signed t-statistic <span class="math inline">\(T=T\left(\theta_{0}\right)\)</span>. The hypothesis <span class="math inline">\(\theta=\theta_{0}\)</span> is rejected in favor of <span class="math inline">\(\theta&gt;\theta_{0}\)</span> if <span class="math inline">\(T&gt;c\)</span> where <span class="math inline">\(c\)</span> satisfies <span class="math inline">\(\alpha=1-\Phi(c)\)</span>. Negative values of <span class="math inline">\(T\)</span> are not taken as evidence against <span class="math inline">\(\mathbb{M}_{0}\)</span>, as point estimates <span class="math inline">\(\widehat{\theta}\)</span> less than <span class="math inline">\(\theta_{0}\)</span> do not point to <span class="math inline">\(\theta&gt;\theta_{0}\)</span>. Since the critical values are taken from the single tail of the normal distribution they are smaller than for two-sided tests. Specifically, the asymptotic <span class="math inline">\(5 %\)</span> critical value is <span class="math inline">\(c=1.645\)</span>. Thus, we reject <span class="math inline">\(\theta=\theta_{0}\)</span> in favor of <span class="math inline">\(\theta&gt;\theta_{0}\)</span> if <span class="math inline">\(T&gt;1.645\)</span>.</p>
<p>Conversely, tests of <span class="math inline">\(\theta=\theta_{0}\)</span> against <span class="math inline">\(\theta&lt;\theta_{0}\)</span> reject <span class="math inline">\(\mathbb{M}_{0}\)</span> for negative t-statistics, e.g.&nbsp;if <span class="math inline">\(T&lt;-c\)</span>. Large positive values of <span class="math inline">\(T\)</span> are not evidence for <span class="math inline">\(\mathbb{H}_{1}: \theta&lt;\theta_{0}\)</span>. An asymptotic <span class="math inline">\(5 %\)</span> test rejects if <span class="math inline">\(T&lt;-1.645\)</span>.</p>
<p>There seems to be an ambiguity. Should we use the two-sided critical value <span class="math inline">\(1.96\)</span> or the one-sided critical value 1.645? The answer is that in most cases the two-sided critical value is appropriate. We should use the one-sided critical values only when the parameter space is known to satisfy a one-sided restriction such as <span class="math inline">\(\theta \geq \theta_{0}\)</span>. This is when the test of <span class="math inline">\(\theta=\theta_{0}\)</span> against <span class="math inline">\(\theta&gt;\theta_{0}\)</span> makes sense. If the restriction <span class="math inline">\(\theta \geq \theta_{0}\)</span> is not known a priori then imposing this restriction to test <span class="math inline">\(\theta=\theta_{0}\)</span> against <span class="math inline">\(\theta&gt;\theta_{0}\)</span> does not makes sense. Since linear regression coefficients typically do not have a priori sign restrictions, the standard convention is to use two-sided critical values.</p>
<p>This may seem contrary to the way testing is presented in statistical textbooks which often focus on one-sided alternative hypotheses. The latter focus is primarily for pedagogy as the one-sided theoretical problem is cleaner and easier to understand.</p>
</section>
<section id="type-ii-error-and-power" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="type-ii-error-and-power"><span class="header-section-number">9.5</span> Type II Error and Power</h2>
<p>A false acceptance of the null hypothesis <span class="math inline">\(\mathbb{H}_{0}\)</span> (accepting <span class="math inline">\(\mathbb{M}_{0}\)</span> when <span class="math inline">\(\mathbb{H}_{1}\)</span> is true) is called a Type II error. The rejection probability under the alternative hypothesis is called the power of the test, and equals 1 minus the probability of a Type II error:</p>
<p><span class="math display">\[
\pi(\theta)=\mathbb{P}\left[\text { Reject } \mathbb{H}_{0} \mid \mathbb{H}_{1} \text { true }\right]=\mathbb{P}\left[T&gt;c \mid \mathbb{M}_{1} \text { true }\right] .
\]</span></p>
<p>We call <span class="math inline">\(\pi(\theta)\)</span> the power function and is written as a function of <span class="math inline">\(\theta\)</span> to indicate its dependence on the true value of the parameter <span class="math inline">\(\theta\)</span>.</p>
<p>In the dominant approach to hypothesis testing the goal of test construction is to have high power subject to the constraint that the size of the test is lower than the pre-specified significance level. Generally, the power of a test depends on the true value of the parameter <span class="math inline">\(\theta\)</span>, and for a well-behaved test the power is increasing both as <span class="math inline">\(\theta\)</span> moves away from the null hypothesis <span class="math inline">\(\theta_{0}\)</span> and as the sample size <span class="math inline">\(n\)</span> increases.</p>
<p>Given the two possible states of the world <span class="math inline">\(\left(\mathbb{M}_{0}\right.\)</span> or <span class="math inline">\(\left.\mathbb{H}_{1}\right)\)</span> and the two possible decisions (Accept <span class="math inline">\(\mathbb{M}_{0}\)</span> or Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> ) there are four possible pairings of states and decisions as is depicted in Table 9.1.</p>
<p>Table 9.1: Hypothesis Testing Decisions</p>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>{Accept <span class="math inline">\(\mathbb{H}_{0}\)</span></th>
<th>{Reject <span class="math inline">\(\mathbb{M}_{0}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathbb{M}_{0}\)</span> true</td>
<td>Correct Decision</td>
<td>Type I Error</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{H}_{1}\)</span> true</td>
<td>Type II Error</td>
<td>Correct Decision</td>
</tr>
</tbody>
</table>
<p>Given a test statistic <span class="math inline">\(T\)</span>, increasing the critical value <span class="math inline">\(c\)</span> increases the acceptance region <span class="math inline">\(S_{0}\)</span> while decreasing the rejection region <span class="math inline">\(S_{1}\)</span>. This decreases the likelihood of a Type I error (decreases the size) but increases the likelihood of a Type II error (decreases the power). Thus the choice of <span class="math inline">\(c\)</span> involves a trade-off between size and the power. This is why the significance level <span class="math inline">\(\alpha\)</span> of the test cannot be set arbitrarily small. Otherwise the test will not have meaningful power.</p>
<p>It is important to consider the power of a test when interpreting hypothesis tests as an overly narrow focus on size can lead to poor decisions. For example, it is easy to design a test which has perfect size yet has trivial power. Specifically, for any hypothesis we can use the following test: Generate a random variable <span class="math inline">\(U \sim U[0,1]\)</span> and reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(U&lt;\alpha\)</span>. This test has exact size of <span class="math inline">\(\alpha\)</span>. Yet the test also has power precisely equal to <span class="math inline">\(\alpha\)</span>. When the power of a test equals the size we say that the test has trivial power. Nothing is learned from such a test.</p>
</section>
<section id="statistical-significance" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="statistical-significance"><span class="header-section-number">9.6</span> Statistical Significance</h2>
<p>Testing requires a pre-selected choice of significance level <span class="math inline">\(\alpha\)</span> yet there is no objective scientific basis for choice of <span class="math inline">\(\alpha\)</span>. Nevertheless, the common practice is to set <span class="math inline">\(\alpha=0.05\)</span> (5%). Alternative common values are <span class="math inline">\(\alpha=0.10(10 %)\)</span> and <span class="math inline">\(\alpha=0.01(1 %)\)</span>. These choices are somewhat the by-product of traditional tables of critical values and statistical software.</p>
<p>The informal reasoning behind the <span class="math inline">\(5 %\)</span> critical value is to ensure that Type I errors should be relatively unlikely - that the decision “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span>” has scientific strength - yet the test retains power against reasonable alternatives. The decision “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span>” means that the evidence is inconsistent with the null hypothesis in the sense that it is relatively unlikely ( 1 in 20) that data generated by the null hypothesis would yield the observed test result.</p>
<p>In contrast, the decision “Accept <span class="math inline">\(\mathbb{H}_{0}\)</span>” is not a strong statement. It does not mean that the evidence supports <span class="math inline">\(\mathbb{M}_{0}\)</span>, only that there is insufficient evidence to reject <span class="math inline">\(\mathbb{M}_{0}\)</span>. Because of this it is more accurate to use the label “Do not Reject <span class="math inline">\(\mathbb{M}_{0}\)</span>” instead of “Accept <span class="math inline">\(\mathbb{H}_{0}\)</span>”.</p>
<p>When a test rejects <span class="math inline">\(\mathbb{M}_{0}\)</span> at the <span class="math inline">\(5 %\)</span> significance level it is common to say that the statistic is statistically significant and if the test accepts <span class="math inline">\(\mathbb{M}_{0}\)</span> it is common to say that the statistic is not statistically significant or that it is statistically insignificant. It is helpful to remember that this is simply a compact way of saying “Using the statistic <span class="math inline">\(T\)</span> the hypothesis <span class="math inline">\(\mathbb{H}_{0}\)</span> can [cannot] be rejected at the asymptotic <span class="math inline">\(5 %\)</span> level.” Furthermore, when the null hypothesis <span class="math inline">\(\mathbb{M}_{0}: \theta=0\)</span> is rejected it is common to say that the coefficient <span class="math inline">\(\theta\)</span> is statistically significant, because the test has rejected the hypothesis that the coefficient is equal to zero.</p>
<p>Let us return to the example about the union wage premium as measured in Table 4.1. The absolute <span class="math inline">\(\mathrm{t}\)</span>-statistic for the coefficient on “Male Union Member” is <span class="math inline">\(0.095 / 0.020=4.7\)</span>, which is greater than the <span class="math inline">\(5 %\)</span> asymptotic critical value of <span class="math inline">\(1.96\)</span>. Therefore we reject the hypothesis that union membership does not affect wages for men. In this case we can say that union membership is statistically significant for men. However, the absolute t-statistic for the coefficient on “Female Union Member” is <span class="math inline">\(0.023 / 0.020=1.2\)</span>, which is less than <span class="math inline">\(1.96\)</span> and therefore we do not reject the hypothesis that union membership does not affect wages for women. In this case we find that membership for women is not statistically significant.</p>
<p>When a test accepts a null hypothesis (when a test is not statistically significant) a common misinterpretation is that this is evidence that the null hypothesis is true. This is incorrect. Failure to reject is by itself not evidence. Without an analysis of power we do not know the likelihood of making a Type II error and thus are uncertain. In our wage example it would be a mistake to write that “the regression finds that female union membership has no effect on wages”. This is an incorrect and most unfortunate interpretation. The test has failed to reject the hypothesis that the coefficient is zero but that does not mean that the coefficient is actually zero.</p>
<p>When a test rejects a null hypothesis (when a test is statistically significant) it is strong evidence against the hypothesis (because if the hypothesis were true then rejection is an unlikely event). Rejection should be taken as evidence against the null hypothesis. However, we can never conclude that the null hypothesis is indeed false as we cannot exclude the possibility that we are making a Type I error.</p>
<p>Perhaps more importantly, there is an important distinction between statistical and economic significance. If we correctly reject the hypothesis <span class="math inline">\(\mathbb{M}_{0}: \theta=0\)</span> it means that the true value of <span class="math inline">\(\theta\)</span> is non-zero. This includes the possibility that <span class="math inline">\(\theta\)</span> may be non-zero but close to zero in magnitude. This only makes sense if we interpret the parameters in the context of their relevant models. In our wage regression example we might consider wage effects of <span class="math inline">\(1 %\)</span> magnitude or less as being “close to zero”. In a log wage regression this corresponds to a dummy variable with a coefficient less than <span class="math inline">\(0.01\)</span>. If the standard error is sufficiently small (less than <span class="math inline">\(0.005\)</span> ) then a coefficient estimate of <span class="math inline">\(0.01\)</span> will be statistically significant but not economically significant. This occurs frequently in applications with very large sample sizes where standard errors can be quite small.</p>
<p>The solution is to focus whenever possible on confidence intervals and the economic meaning of the coefficients. For example, if the coefficient estimate is <span class="math inline">\(0.005\)</span> with a standard error of <span class="math inline">\(0.002\)</span> then a <span class="math inline">\(95 %\)</span> confidence interval would be <span class="math inline">\([0.001,0.009]\)</span> indicating that the true effect is likely between <span class="math inline">\(0 %\)</span> and <span class="math inline">\(1 %\)</span>, and hence is slightly positive but small. This is much more informative than the misleading statement “the effect is statistically positive”.</p>
</section>
<section id="p-values" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="p-values"><span class="header-section-number">9.7</span> P-Values</h2>
<p>Continuing with the wage regression estimates reported in Table 4.1, consider another question: Does marriage status affect wages? To test the hypothesis that marriage status has no effect on wages, we examine the t-statistics for the coefficients on “Married Male” and “Married Female” in Table 4.1, which are <span class="math inline">\(0.211 / 0.010=22\)</span> and <span class="math inline">\(0.016 / 0.010=1.7\)</span>, respectively. The first exceeds the asymptotic <span class="math inline">\(5 %\)</span> critical value of <span class="math inline">\(1.96\)</span> so we reject the hypothesis for men. The second is smaller than <span class="math inline">\(1.96\)</span> so we fail to reject the hypothesis for women. Taking a second look at the statistics we see that the statistic for men (22) is exceptionally high and that for women (1.7) is only slightly below the critical value. Suppose that the <span class="math inline">\(\mathrm{t}\)</span>-statistic for women were slightly increased to 2.0. This is larger than the critical value so would lead to the decision “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span>” rather than “Accept <span class="math inline">\(\mathbb{M}_{0}\)</span>”. Should we really be making a different decision if the <span class="math inline">\(\mathrm{t}\)</span>-statistic is <span class="math inline">\(2.0\)</span> rather than 1.7? The difference in values is small, shouldn’t the difference in the decision be also small? Thinking through these examples it seems unsatisfactory to simply report “Accept <span class="math inline">\(\mathbb{M}_{0}\)</span>” or “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span>”. These two decisions do not summarize the evidence. Instead, the magnitude of the statistic <span class="math inline">\(T\)</span> suggests a “degree of evidence” against <span class="math inline">\(\mathbb{H}_{0}\)</span>. How can we take this into account?</p>
<p>The answer is to report what is known as the asymptotic p-value</p>
<p><span class="math display">\[
p=1-G(T) .
\]</span></p>
<p>Since the distribution function <span class="math inline">\(G\)</span> is monotonically increasing, the p-value is a monotonically decreasing function of <span class="math inline">\(T\)</span> and is an equivalent test statistic. Instead of rejecting <span class="math inline">\(\mathbb{R}_{0}\)</span> at the significance level <span class="math inline">\(\alpha\)</span> if <span class="math inline">\(T&gt;c\)</span>, we can reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(p&lt;\alpha\)</span>. Thus it is sufficient to report <span class="math inline">\(p\)</span>, and let the reader decide. In practice, the p-value is calculated numerically. For example, in MATLAB the command is <span class="math inline">\(2 *(1-\operatorname{normal} c d f(\mathrm{abs}(\mathrm{t})))\)</span>.</p>
<p>It is instructive to interpret <span class="math inline">\(p\)</span> as the marginal significance level: the smallest value of <span class="math inline">\(\alpha\)</span> for which the test <span class="math inline">\(T\)</span> “rejects” the null hypothesis. That is, <span class="math inline">\(p=0.11\)</span> means that <span class="math inline">\(T\)</span> rejects <span class="math inline">\(\mathbb{H}_{0}\)</span> for all significance levels greater than <span class="math inline">\(0.11\)</span>, but fails to reject <span class="math inline">\(\mathbb{M}_{0}\)</span> for significance levels less than <span class="math inline">\(0.11\)</span>.</p>
<p>Furthermore, the asymptotic p-value has a very convenient asymptotic null distribution. Since <span class="math inline">\(T-\vec{d}\)</span> <span class="math inline">\(\xi\)</span> under <span class="math inline">\(\mathbb{M}_{0}\)</span>, then <span class="math inline">\(p=1-G(T) \underset{d}{\longrightarrow} 1-G(\xi)\)</span>, which has the distribution</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{P}[1-G(\xi) \leq u] &amp;=\mathbb{P}[1-u \leq G(\xi)] \\
&amp;=1-\mathbb{P}\left[\xi \leq G^{-1}(1-u)\right] \\
&amp;=1-G\left(G^{-1}(1-u)\right) \\
&amp;=1-(1-u) \\
&amp;=u,
\end{aligned}
\]</span></p>
<p>which is the uniform distribution on <span class="math inline">\([0,1]\)</span>. (This calculation assumes that <span class="math inline">\(G(u)\)</span> is strictly increasing which is true for conventional asymptotic distributions such as the normal.) Thus <span class="math inline">\(p \underset{d}{\longrightarrow} U[0,1]\)</span>. This means that the “unusualness” of <span class="math inline">\(p\)</span> is easier to interpret than the “unusualness” of <span class="math inline">\(T\)</span>.</p>
<p>An important caveat is that the <span class="math inline">\(\mathrm{p}\)</span>-value <span class="math inline">\(p\)</span> should not be interpreted as the probability that either hypothesis is true. A common mis-interpretation is that <span class="math inline">\(p\)</span> is the probability “that the null hypothesis is true.” This is incorrect. Rather, <span class="math inline">\(p\)</span> is the marginal significance level-a measure of the strength of information against the null hypothesis. For a t-statistic the p-value can be calculated either using the normal distribution or the student <span class="math inline">\(t\)</span> distribution, the latter presented in Section 5.12. p-values calculated using the student <span class="math inline">\(t\)</span> will be slightly larger, though the difference is small when the sample size is large.</p>
<p>Returning to our empirical example, for the test that the coefficient on “Married Male” is zero the pvalue is <span class="math inline">\(0.000\)</span>. This means that it would be nearly impossible to observe a t-statistic as large as 22 when the true value of the coefficient is zero. When presented with such evidence we can say that we “strongly reject” the null hypothesis, that the test is “highly significant”, or that “the test rejects at any conventional critical value”. In contrast, the p-value for the coefficient on “Married Female” is <span class="math inline">\(0.094\)</span>. In this context it is typical to say that the test is “close to significant”, meaning that the p-value is larger than <span class="math inline">\(0.05\)</span>, but not too much larger.</p>
<p>A related but inferior empirical practice is to append asterisks <span class="math inline">\((*)\)</span> to coefficient estimates or test statistics to indicate the level of significance. A common practice to to append a single asterisk (\textit{) for an estimate or test statistic which exceeds the <span class="math inline">\(10 %\)</span> critical value (i.e., is significant at the <span class="math inline">\(10 %\)</span> level), append a double asterisk (<strong>) for a test which exceeds the <span class="math inline">\(5 %\)</span> critical value, and append a triple asterisk (</strong>}) for a test which exceeds the <span class="math inline">\(1 %\)</span> critical value. Such a practice can be better than a table of raw test statistics as the asterisks permit a quick interpretation of significance. On the other hand, asterisks are inferior to p-values, which are also easy and quick to interpret. The goal is essentially the same; it is wiser to report p-values whenever possible and avoid the use of asterisks.</p>
<p>Our recommendation is that the best empirical practice is to compute and report the asymptotic pvalue <span class="math inline">\(p\)</span> rather than simply the test statistic <span class="math inline">\(T\)</span>, the binary decision Accept/Reject, or appending asterisks. The p-value is a simple statistic, easy to interpret, and contains more information than the other choices.</p>
<p>We now summarize the main features of hypothesis testing.</p>
<ol type="1">
<li><p>Select a significance level <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p>Select a test statistic <span class="math inline">\(T\)</span> with asymptotic distribution <span class="math inline">\(T \underset{d}{\rightarrow} \xi\)</span> under <span class="math inline">\(\mathbb{H}_{0}\)</span>.</p></li>
<li><p>Set the asymptotic critical value <span class="math inline">\(c\)</span> so that <span class="math inline">\(1-G(c)=\alpha\)</span>, where <span class="math inline">\(G\)</span> is the distribution function of <span class="math inline">\(\xi\)</span>.</p></li>
<li><p>Calculate the asymptotic p-value <span class="math inline">\(p=1-G(T)\)</span>.</p></li>
<li><p>Reject <span class="math inline">\(\mathbb{R}_{0}\)</span> if <span class="math inline">\(T&gt;c\)</span>, or equivalently <span class="math inline">\(p&lt;\alpha\)</span>.</p></li>
<li><p>Accept <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(T \leq c\)</span>, or equivalently <span class="math inline">\(p \geq \alpha\)</span>.</p></li>
<li><p>Report <span class="math inline">\(p\)</span> to summarize the evidence concerning <span class="math inline">\(\mathbb{M}_{0}\)</span> versus <span class="math inline">\(\mathbb{M}_{1}\)</span>.</p></li>
</ol>
</section>
<section id="t-ratios-and-the-abuse-of-testing" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="t-ratios-and-the-abuse-of-testing"><span class="header-section-number">9.8</span> t-ratios and the Abuse of Testing</h2>
<p>In Section <span class="math inline">\(4.19\)</span> we argued that a good applied practice is to report coefficient estimates <span class="math inline">\(\widehat{\theta}\)</span> and standard errors <span class="math inline">\(s(\widehat{\theta})\)</span> for all coefficients of interest in estimated models. With <span class="math inline">\(\widehat{\theta}\)</span> and <span class="math inline">\(s(\widehat{\theta})\)</span> the reader can easily construct confidence intervals <span class="math inline">\([\widehat{\theta} \pm 2 s(\widehat{\theta})]\)</span> and t-statistics <span class="math inline">\(\left(\widehat{\theta}-\theta_{0}\right) / s(\widehat{\theta})\)</span> for hypotheses of interest.</p>
<p>Some applied papers (especially older ones) report t-ratios <span class="math inline">\(T=\widehat{\theta} / s(\widehat{\theta})\)</span> instead of standard errors. This is poor econometric practice. While the same information is being reported (you can back out standard errors by division, e.g.&nbsp;<span class="math inline">\(s(\widehat{\theta})=\widehat{\theta} / T)\)</span>, standard errors are generally more helpful to readers than t-ratios. Standard errors help the reader focus on the estimation precision and confidence intervals, while t-ratios focus attention on statistical significance. While statistical significance is important, it is less important that the parameter estimates themselves and their confidence intervals. The focus should be on the meaning of the parameter estimates, their magnitudes, and their interpretation, not on listing which variables have significant (e.g.&nbsp;non-zero) coefficients. In many modern applications sample sizes are very large so standard errors can be very small. Consequently t-ratios can be large even if the coefficient estimates are economically small. In such contexts it may not be interesting to announce “The coefficient is non-zero!” Instead, what is interesting to announce is that “The coefficient estimate is economically interesting!”</p>
<p>In particular, some applied papers report coefficient estimates and t-ratios and limit their discussion of the results to describing which variables are “significant” (meaning that their t-ratios exceed 2) and the signs of the coefficient estimates. This is very poor empirical work and should be studiously avoided. It is also a recipe for banishment of your work to lower tier economics journals.</p>
<p>Fundamentally, the common t-ratio is a test for the hypothesis that a coefficient equals zero. This should be reported and discussed when this is an interesting economic hypothesis of interest. But if this is not the case it is distracting.</p>
<p>One problem is that standard packages, such as Stata, by default report t-statistics and p-values for every estimated coefficient. While this can be useful (as a user doesn’t need to explicitly ask to test a desired coefficient) it can be misleading as it may unintentionally suggest that the entire list of t-statistics and p-values are important. Instead, a user should focus on tests of scientifically motivated hypotheses.</p>
<p>In general, when a coefficient <span class="math inline">\(\theta\)</span> is of interest it is constructive to focus on the point estimate, its standard error, and its confidence interval. The point estimate gives our “best guess” for the value. The standard error is a measure of precision. The confidence interval gives us the range of values consistent with the data. If the standard error is large then the point estimate is not a good summary about <span class="math inline">\(\theta\)</span>. The endpoints of the confidence interval describe the bounds on the likely possibilities. If the confidence interval embraces too broad a set of values for <span class="math inline">\(\theta\)</span> then the dataset is not sufficiently informative to render useful inferences about <span class="math inline">\(\theta\)</span>. On the other hand if the confidence interval is tight then the data have produced an accurate estimate and the focus should be on the value and interpretation of this estimate. In contrast, the statement “the t-ratio is highly significant” has little interpretive value.</p>
<p>The above discussion requires that the researcher knows what the coefficient <span class="math inline">\(\theta\)</span> means (in terms of the economic problem) and can interpret values and magnitudes, not just signs. This is critical for good applied econometric practice.</p>
<p>For example, consider the question about the effect of marriage status on mean log wages. We had found that the effect is “highly significant” for men and “close to significant” for women. Now, let’s construct asymptotic <span class="math inline">\(95 %\)</span> confidence intervals for the coefficients. The one for men is <span class="math inline">\([0.19,0.23]\)</span> and that for women is <span class="math inline">\([-0.00,0.03]\)</span>. This shows that average wages for married men are about <span class="math inline">\(19-23 %\)</span> higher than for unmarried men, which is substantial, while the difference for women is about 0-3%, which is small. These magnitudes are more informative than the results of the hypothesis tests.</p>
</section>
<section id="wald-tests" class="level2" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="wald-tests"><span class="header-section-number">9.9</span> Wald Tests</h2>
<p>The t-test is appropriate when the null hypothesis is a real-valued restriction. More generally there may be multiple restrictions on the coefficient vector <span class="math inline">\(\beta\)</span>. Suppose that we have <span class="math inline">\(q&gt;1\)</span> restrictions which can be written in the form (9.1). It is natural to estimate <span class="math inline">\(\theta=r(\beta)\)</span> by the plug-in estimator <span class="math inline">\(\widehat{\theta}=r(\widehat{\beta})\)</span>. To test <span class="math inline">\(\mathbb{H}_{0}: \theta=\theta_{0}\)</span> against <span class="math inline">\(\mathbb{H}_{1}: \theta \neq \theta_{0}\)</span> one approach is to measure the magnitude of the discrepancy <span class="math inline">\(\widehat{\theta}-\theta_{0}\)</span>. As this is a vector there is more than one measure of its length. One simple measure is the weighted quadratic form known as the Wald statistic. This is (7.37) evaluated at the null hypothesis</p>
<p><span class="math display">\[
W=W\left(\theta_{0}\right)=\left(\widehat{\theta}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\theta}}^{-1}\left(\widehat{\theta}-\theta_{0}\right)
\]</span></p>
<p>where <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\theta}}=\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \widehat{\boldsymbol{R}}\)</span> is an estimator of <span class="math inline">\(\boldsymbol{V}_{\widehat{\theta}}\)</span> and <span class="math inline">\(\widehat{\boldsymbol{R}}=\frac{\partial}{\partial \beta} r(\widehat{\beta})^{\prime}\)</span>. Notice that we can write <span class="math inline">\(W\)</span> alternatively as</p>
<p><span class="math display">\[
W=n\left(\widehat{\theta}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{V}}_{\theta}^{-1}\left(\widehat{\theta}-\theta_{0}\right)
\]</span></p>
<p>using the asymptotic variance estimator <span class="math inline">\(\widehat{\boldsymbol{V}}_{\theta}\)</span>, or we can write it directly as a function of <span class="math inline">\(\widehat{\beta}\)</span> as</p>
<p><span class="math display">\[
W=\left(r(\widehat{\beta})-\theta_{0}\right)^{\prime}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \widehat{\boldsymbol{R}}\right)^{-1}\left(r(\widehat{\beta})-\theta_{0}\right) .
\]</span></p>
<p>Also, when <span class="math inline">\(r(\beta)=\boldsymbol{R}^{\prime} \beta\)</span> is a linear function of <span class="math inline">\(\beta\)</span>, then the Wald statistic simplifies to</p>
<p><span class="math display">\[
W=\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) .
\]</span></p>
<p>The Wald statistic <span class="math inline">\(W\)</span> is a weighted Euclidean measure of the length of the vector <span class="math inline">\(\widehat{\theta}-\theta_{0}\)</span>. When <span class="math inline">\(q=1\)</span> then <span class="math inline">\(W=T^{2}\)</span>, the square of the t-statistic, so hypothesis tests based on <span class="math inline">\(W\)</span> and <span class="math inline">\(|T|\)</span> are equivalent. The Wald statistic (9.6) is a generalization of the t-statistic to the case of multiple restrictions. As the Wald statistic is symmetric in the argument <span class="math inline">\(\widehat{\theta}-\theta_{0}\)</span> it treats positive and negative alternatives symmetrically. Thus the inherent alternative is always two-sided.</p>
<p>As shown in Theorem 7.13, when <span class="math inline">\(\beta\)</span> satisfies <span class="math inline">\(r(\beta)=\theta_{0}\)</span> then <span class="math inline">\(W \underset{d}{\rightarrow} \chi_{q}^{2}\)</span>, a chi-square random variable with <span class="math inline">\(q\)</span> degrees of freedom. Let <span class="math inline">\(G_{q}(u)\)</span> denote the <span class="math inline">\(\chi_{q}^{2}\)</span> distribution function. For a given significance level <span class="math inline">\(\alpha\)</span> the asymptotic critical value <span class="math inline">\(c\)</span> satisfies <span class="math inline">\(\alpha=1-G_{q}(c)\)</span>. For example, the <span class="math inline">\(5 %\)</span> critical values for <span class="math inline">\(q=1, q=2\)</span>, and <span class="math inline">\(q=3\)</span> are <span class="math inline">\(3.84,5.99\)</span>, and <span class="math inline">\(7.82\)</span>, respectively, and in general the level <span class="math inline">\(\alpha\)</span> critical value can be calculated in MATLAB as chi2inv <span class="math inline">\((1-\alpha, q)\)</span>. An asymptotic test rejects <span class="math inline">\(\mathbb{M}_{0}\)</span> in favor of <span class="math inline">\(\mathbb{M}_{1}\)</span> if <span class="math inline">\(W&gt;c\)</span>. As with t-tests, it is conventional to describe a Wald test as “significant” if <span class="math inline">\(W\)</span> exceeds the <span class="math inline">\(5 %\)</span> asymptotic critical value.</p>
<p>Theorem 9.2 Under Assumptions 7.2, 7.3, 7.4, and <span class="math inline">\(\mathbb{M}_{0}: \theta=\theta_{0} \in \mathbb{R}^{q}\)</span>, then <span class="math inline">\(W \vec{d}\)</span> <span class="math inline">\(\chi_{q}^{2}\)</span>. For <span class="math inline">\(c\)</span> satisfying <span class="math inline">\(\alpha=1-G_{q}(c), \mathbb{P}\left(W&gt;c \mid \mathbb{H}_{0}\right) \longrightarrow \alpha\)</span> so the test “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(W&gt;c\)</span>” has asymptotic size <span class="math inline">\(\alpha\)</span>.</p>
<p>Notice that the asymptotic distribution in Theorem <span class="math inline">\(9.2\)</span> depends solely on <span class="math inline">\(q\)</span>, the number of restrictions being tested. It does not depend on <span class="math inline">\(k\)</span>, the number of parameters estimated.</p>
<p>The asymptotic p-value for <span class="math inline">\(W\)</span> is <span class="math inline">\(p=1-G_{q}(W)\)</span>, and this is particularly useful when testing multiple restrictions. For example, if you write that a Wald test on eight restrictions ( <span class="math inline">\(q=8\)</span> ) has the value <span class="math inline">\(W=\)</span> <span class="math inline">\(11.2\)</span> it is difficult for a reader to assess the magnitude of this statistic unless they have quick access to a statistical table or software. Instead, if you write that the p-value is <span class="math inline">\(p=0.19\)</span> (as is the case for <span class="math inline">\(W=11.2\)</span> and <span class="math inline">\(q=8\)</span> ) then it is simple for a reader to interpret its magnitude as “insignificant”. To calculate the asymptotic p-value for a Wald statistic in MATLAB use the command <span class="math inline">\(1-\operatorname{ch} i 2 c d f(w, q)\)</span>.</p>
<p>Some packages (including Stata) and papers report <span class="math inline">\(F\)</span> versions of Wald statistics. For any Wald statistic <span class="math inline">\(W\)</span> which tests a <span class="math inline">\(q\)</span>-dimensional restriction, the <span class="math inline">\(F\)</span> version of the test is</p>
<p><span class="math display">\[
F=W / q .
\]</span></p>
<p>When <span class="math inline">\(F\)</span> is reported, it is conventional to use <span class="math inline">\(F_{q, n-k}\)</span> critical values and <span class="math inline">\(\mathrm{p}\)</span>-values rather than <span class="math inline">\(\chi_{q}^{2}\)</span> values. The connection between Wald and F statistics is demonstrated in Section <span class="math inline">\(9.14\)</span> where we show that when Wald statistics are calculated using a homoskedastic covariance matrix then <span class="math inline">\(F=W / q\)</span> is identicial to the F statistic of (5.19). While there is no formal justification to using the <span class="math inline">\(F_{q, n-k}\)</span> distribution for nonhomoskedastic covariance matrices, the <span class="math inline">\(F_{q, n-k}\)</span> distribution provides continuity with the exact distribution theory under normality and is a bit more conservative than the <span class="math inline">\(\chi_{q}^{2}\)</span> distribution. (Furthermore, the difference is small when <span class="math inline">\(n-k\)</span> is moderately large.)</p>
<p>To implement a test of zero restrictions in Stata an easy method is to use the command test X1 X2 where X1 and X2 are the names of the variables whose coefficients are hypothesized to equal zero. The <span class="math inline">\(F\)</span> version of the Wald statistic is reported using the covariance matrix calculated by the method specified in the regression command. A p-value is reported, calculated using the <span class="math inline">\(F_{q, n-k}\)</span> distribution.</p>
<p>To illustrate, consider the empirical results presented in Table 4.1. The hypothesis “Union membership does not affect wages” is the joint restriction that both coefficients on “Male Union Member” and “Female Union Member” are zero. We calculate the Wald statistic for this joint hypothesis and find <span class="math inline">\(W=23\)</span> (or <span class="math inline">\(F=12.5\)</span> ) with a p-value of <span class="math inline">\(p=0.000\)</span>. Thus we reject the null hypothesis in favor of the alternative that at least one of the coefficients is non-zero. This does not mean that both coefficients are non-zero, just that one of the two is non-zero. Therefore examining both the joint Wald statistic and the individual t-statistics is useful for interpretation.</p>
<p>As a second example from the same regression, take the hypothesis that married status has no effect on mean wages for women. This is the joint restriction that the coefficients on “Married Female” and “Formerly Married Female” are zero. The Wald statistic for this hypothesis is <span class="math inline">\(W=6.4(F=3.2)\)</span> with a p-value of <span class="math inline">\(0.04\)</span>. Such a p-value is typically called “marginally significant” in the sense that it is slightly smaller than <span class="math inline">\(0.05\)</span>.</p>
<p>The Wald statistic was proposed by Wald (1943).</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-11.jpg" class="img-fluid"></p>
</section>
<section id="homoskedastic-wald-tests" class="level2" data-number="9.10">
<h2 data-number="9.10" class="anchored" data-anchor-id="homoskedastic-wald-tests"><span class="header-section-number">9.10</span> Homoskedastic Wald Tests</h2>
<p>If the error is known to be homoskedastic then it is appropriate to use the homoskedastic Wald statistic (7.38) which replaces <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\theta}}\)</span> with the homoskedastic estimator <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\theta}}^{0}\)</span>. This statistic equals</p>
<p><span class="math display">\[
\begin{aligned}
W^{0} &amp;=\left(\widehat{\theta}-\theta_{0}\right)^{\prime}\left(\widehat{\boldsymbol{V}}_{\widehat{\theta}}^{0}\right)^{-1}\left(\widehat{\theta}-\theta_{0}\right) \\
&amp;=\left(r(\widehat{\beta})-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \widehat{\boldsymbol{R}}\right)^{-1}\left(r(\widehat{\beta})-\theta_{0}\right) / s^{2} .
\end{aligned}
\]</span></p>
<p>In the case of linear hypotheses <span class="math inline">\(\mathbb{M}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span> we can write this as</p>
<p><span class="math display">\[
W^{0}=\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) / s^{2} .
\]</span></p>
<p>We call <span class="math inline">\(W^{0}\)</span> a homoskedastic Wald statistic as it is appropriate when the errors are conditionally homoskedastic.</p>
<p>When <span class="math inline">\(q=1\)</span> then <span class="math inline">\(W^{0}=T^{2}\)</span>, the square of the t-statistic where the latter is computed with a homoskedastic standard error. Theorem 9.3 Under Assumptions <span class="math inline">\(7.2\)</span> and 7.3, <span class="math inline">\(\mathbb{E}\left[e^{2} \mid X\right]=\sigma^{2}&gt;0\)</span>, and <span class="math inline">\(\mathbb{M}_{0}: \theta=\)</span> <span class="math inline">\(\theta_{0} \in \mathbb{R}^{q}\)</span>, then <span class="math inline">\(W^{0} \underset{d}{\longrightarrow} \chi_{q}^{2}\)</span>. For <span class="math inline">\(c\)</span> satisfying <span class="math inline">\(\alpha=1-G_{q}(c), \mathbb{P}\left[W^{0}&gt;c \mid \mathbb{H}_{0}\right] \longrightarrow \alpha\)</span> so the test “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(W^{0}&gt;c\)</span>” has asymptotic size <span class="math inline">\(\alpha\)</span>.</p>
</section>
<section id="criterion-based-tests" class="level2" data-number="9.11">
<h2 data-number="9.11" class="anchored" data-anchor-id="criterion-based-tests"><span class="header-section-number">9.11</span> Criterion-Based Tests</h2>
<p>The Wald statistic is based on the length of the vector <span class="math inline">\(\widehat{\theta}-\theta_{0}\)</span> : the discrepancy between the estimator <span class="math inline">\(\widehat{\theta}=r(\widehat{\beta})\)</span> and the hypothesized value <span class="math inline">\(\theta_{0}\)</span>. An alternative class of tests is based on the discrepancy between the criterion function minimized with and without the restriction.</p>
<p>Criterion-based testing applies when we have a criterion function, say <span class="math inline">\(J(\beta)\)</span> with <span class="math inline">\(\beta \in B\)</span>, which is minimized for estimation, and the goal is to test <span class="math inline">\(\mathbb{M}_{0}: \beta \in B_{0}\)</span> versus <span class="math inline">\(\mathbb{M}_{1}: \beta \notin B_{0}\)</span> where <span class="math inline">\(B_{0} \subset \beta\)</span>. Minimizing the criterion function over <span class="math inline">\(B\)</span> and <span class="math inline">\(B_{0}\)</span> we obtain the unrestricted and restricted estimators</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\widehat{\beta}=\underset{\beta \in B}{\operatorname{argmin}} J(\beta) \\
&amp;\widetilde{\beta}=\underset{\beta \in B_{0}}{\operatorname{argmin}} J(\beta) .
\end{aligned}
\]</span></p>
<p>The criterion-based statistic for <span class="math inline">\(\mathbb{H}_{0}\)</span> versus <span class="math inline">\(\mathbb{H}_{1}\)</span> is proportional to</p>
<p><span class="math display">\[
J=\min _{\beta \in B_{0}} J(\beta)-\min _{\beta \in B} J(\beta)=J(\widetilde{\beta})-J(\widehat{\beta}) .
\]</span></p>
<p>The criterion-based statistic <span class="math inline">\(J\)</span> is sometimes called a distance statistic, a minimum-distance statistic, or a likelihood-ratio-like statistic.</p>
<p>Since <span class="math inline">\(B_{0}\)</span> is a subset of <span class="math inline">\(B, J(\widetilde{\beta}) \geq J(\widehat{\beta})\)</span> and thus <span class="math inline">\(J \geq 0\)</span>. The statistic <span class="math inline">\(J\)</span> measures the cost on the criterion of imposing the null restriction <span class="math inline">\(\beta \in B_{0}\)</span>.</p>
</section>
<section id="minimum-distance-tests" class="level2" data-number="9.12">
<h2 data-number="9.12" class="anchored" data-anchor-id="minimum-distance-tests"><span class="header-section-number">9.12</span> Minimum Distance Tests</h2>
<p>The minimum distance test is based on the minimum distance criterion (8.19)</p>
<p><span class="math display">\[
J(\beta)=n(\widehat{\beta}-\beta)^{\prime} \widehat{\boldsymbol{W}}(\widehat{\beta}-\beta)
\]</span></p>
<p>with <span class="math inline">\(\widehat{\beta}\)</span> the unrestricted least squares estimator. The restricted estimator <span class="math inline">\(\widetilde{\beta}_{\text {md }}\)</span> minimizes (9.8) subject to <span class="math inline">\(\beta \in B_{0}\)</span>. Observing that <span class="math inline">\(J(\widehat{\beta})=0\)</span>, the minimum distance statistic simplifies to</p>
<p><span class="math display">\[
J=J\left(\widetilde{\beta}_{\mathrm{md}}\right)=n\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{md}}\right)^{\prime} \widehat{\boldsymbol{W}}\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{md}}\right) .
\]</span></p>
<p>The efficient minimum distance estimator <span class="math inline">\(\widetilde{\beta}_{\mathrm{emd}}\)</span> is obtained by setting <span class="math inline">\(\widehat{\boldsymbol{W}}=\widehat{\boldsymbol{V}}_{\beta}^{-1}\)</span> in (9.8) and (9.9). The efficient minimum distance statistic for <span class="math inline">\(\mathbb{H}_{0}: \beta \in B_{0}\)</span> is therefore</p>
<p><span class="math display">\[
J^{*}=n\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime} \widehat{\boldsymbol{V}}_{\beta}^{-1}\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}\right) .
\]</span></p>
<p>Consider the class of linear hypotheses <span class="math inline">\(\mathbb{M}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span>. In this case we know from (8.25) that the efficient minimum distance estimator <span class="math inline">\(\widetilde{\beta}_{\mathrm{emd}}\)</span> subject to the constraint <span class="math inline">\(\boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span> is</p>
<p><span class="math display">\[
\widetilde{\beta}_{\mathrm{emd}}=\widehat{\beta}-\widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)
\]</span></p>
<p>and thus</p>
<p><span class="math display">\[
\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}=\widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) .
\]</span></p>
<p>Substituting into (9.10) we find</p>
<p><span class="math display">\[
\begin{aligned}
J^{*} &amp;=n\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1} \boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{V}}_{\boldsymbol{\beta}}^{-1} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) \\
&amp;=n\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) \\
&amp;=W,
\end{aligned}
\]</span></p>
<p>which is the Wald statistic (9.6).</p>
<p>Thus for linear hypotheses <span class="math inline">\(\mathbb{H}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span>, the efficient minimum distance statistic <span class="math inline">\(J^{*}\)</span> is identical to the Wald statistic (9.6). For nonlinear hypotheses, however, the Wald and minimum distance statistics are different.</p>
<p>Newey and West (1987a) established the asymptotic null distribution of <span class="math inline">\(J^{*}\)</span>.</p>
<p>Theorem 9.4 Under Assumptions <span class="math inline">\(7.2,7.3,7.4\)</span>, and <span class="math inline">\(\mathbb{H}_{0}: \theta=\theta_{0} \in \mathbb{R}^{q}, J^{*} \underset{d}{\longrightarrow} \chi_{q}^{2}\)</span>.</p>
<p>Testing using the minimum distance statistic <span class="math inline">\(J^{*}\)</span> is similar to testing using the Wald statistic <span class="math inline">\(W\)</span>. Critical values and p-values are computed using the <span class="math inline">\(\chi_{q}^{2}\)</span> distribution. <span class="math inline">\(\mathbb{H}_{0}\)</span> is rejected in favor of <span class="math inline">\(\mathbb{H}_{1}\)</span> if <span class="math inline">\(J^{*}\)</span> exceeds the level <span class="math inline">\(\alpha\)</span> critical value, which can be calculated in MATLAB as chi2inv <span class="math inline">\((1-\alpha, q)\)</span>. The asymptotic pvalue is <span class="math inline">\(p=1-G_{q}\left(J^{*}\right)\)</span>. In MATLAB, use the command <span class="math inline">\(1-\operatorname{chi} 2 \mathrm{cdf}(\mathrm{J}, \mathrm{q})\)</span>.</p>
<p>We now demonstrate Theorem 9.4. The conditions of Theorem <span class="math inline">\(8.10\)</span> hold, because <span class="math inline">\(\mathbb{H}_{0}\)</span> implies Assumption 8.1. From (8.54) with <span class="math inline">\(\widehat{\boldsymbol{W}}=\widehat{\boldsymbol{V}}_{\beta}\)</span>, we see that</p>
<p><span class="math display">\[
\begin{aligned}
\sqrt{n}\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}\right) &amp;=\widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\left(\boldsymbol{R}_{n}^{* \prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \boldsymbol{R}_{n}^{* \prime} \sqrt{n}(\widehat{\beta}-\beta) \\
&amp; \underset{d}{\longrightarrow} \boldsymbol{V}_{\beta} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta} \boldsymbol{R}\right)^{-1} \boldsymbol{R}^{\prime} \mathrm{N}\left(0, \boldsymbol{V}_{\beta}\right)=\boldsymbol{V}_{\beta} \boldsymbol{R} Z
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(Z \sim \mathrm{N}\left(0,\left(\boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta} \boldsymbol{R}\right)^{-1}\right)\)</span>. Thus</p>
<p><span class="math display">\[
J^{*}=n\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime} \widehat{\boldsymbol{V}}_{\beta}^{-1}\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{emd}}\right) \underset{d}{\longrightarrow} Z^{\prime} \boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta} \boldsymbol{V}_{\beta}^{-1} \boldsymbol{V}_{\beta} \boldsymbol{R} Z=Z^{\prime}\left(\boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta} \boldsymbol{R}\right) Z=\chi_{q}^{2}
\]</span></p>
<p>as claimed.</p>
</section>
<section id="minimum-distance-tests-under-homoskedasticity" class="level2" data-number="9.13">
<h2 data-number="9.13" class="anchored" data-anchor-id="minimum-distance-tests-under-homoskedasticity"><span class="header-section-number">9.13</span> Minimum Distance Tests Under Homoskedasticity</h2>
<p>If we set <span class="math inline">\(\widehat{\boldsymbol{W}}=\widehat{\boldsymbol{Q}}_{X X} / s^{2}\)</span> in (9.8) we obtain the criterion (8.20)</p>
<p><span class="math display">\[
J^{0}(\beta)=n(\widehat{\beta}-\beta)^{\prime} \widehat{\boldsymbol{Q}}_{X X}(\widehat{\beta}-\beta) / s^{2} .
\]</span></p>
<p>A minimum distance statistic for <span class="math inline">\(\mathbb{\Perp}_{0}: \beta \in B_{0}\)</span> is</p>
<p><span class="math display">\[
J^{0}=\min _{\beta \in B_{0}} J^{0}(\beta) .
\]</span></p>
<p>Equation (8.21) showed that <span class="math inline">\(\operatorname{SSE}(\beta)=n \widehat{\sigma}^{2}+s^{2} J^{0}(\beta)\)</span>. So the minimizers of <span class="math inline">\(\operatorname{SSE}(\beta)\)</span> and <span class="math inline">\(J^{0}(\beta)\)</span> are identical. Thus the constrained minimizer of <span class="math inline">\(J^{0}(\beta)\)</span> is constrained least squares</p>
<p><span class="math display">\[
\widetilde{\beta}_{\text {cls }}=\underset{\beta \in B_{0}}{\operatorname{argmin}} J^{0}(\beta)=\underset{\beta \in B_{0}}{\operatorname{argmin}} \operatorname{SSE}(\beta)
\]</span></p>
<p>and therefore</p>
<p><span class="math display">\[
J_{n}^{0}=J_{n}^{0}\left(\widetilde{\beta}_{\mathrm{cls}}\right)=n\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{cls}}\right)^{\prime} \widehat{\boldsymbol{Q}}_{X X}\left(\widehat{\beta}-\widetilde{\beta}_{\mathrm{cls}}\right) / s^{2} .
\]</span></p>
<p>In the special case of linear hypotheses <span class="math inline">\(\mathbb{M}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span>, the constrained least squares estimator subject to <span class="math inline">\(\boldsymbol{R}^{\prime} \beta=\theta_{0}\)</span> has the solution (8.9)</p>
<p><span class="math display">\[
\widetilde{\beta}_{\mathrm{cls}}=\widehat{\beta}-\widehat{\boldsymbol{Q}}_{X X}^{-1} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{Q}}_{X X}^{-1} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)
\]</span></p>
<p>and solving we find</p>
<p><span class="math display">\[
J^{0}=n\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right)^{\prime}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{Q}}_{X X}^{-1} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\theta_{0}\right) / s^{2}=W^{0} .
\]</span></p>
<p>This is the homoskedastic Wald statistic (9.7). Thus for testing linear hypotheses, homoskedastic minimum distance and Wald statistics agree.</p>
<p>For nonlinear hypotheses they disagree, but have the same null asymptotic distribution.</p>
<p>Theorem 9.5 Under Assumptions <span class="math inline">\(7.2\)</span> and <span class="math inline">\(7.3, \mathbb{E}\left[e^{2} \mid X\right]=\sigma^{2}&gt;0\)</span>, and <span class="math inline">\(\mathbb{M}_{0}: \theta=\)</span> <span class="math inline">\(\theta_{0} \in \mathbb{R}^{q}\)</span>, then <span class="math inline">\(J^{0} \underset{d}{\longrightarrow} \chi_{q}^{2}\)</span></p>
</section>
<section id="f-tests" class="level2" data-number="9.14">
<h2 data-number="9.14" class="anchored" data-anchor-id="f-tests"><span class="header-section-number">9.14</span> F Tests</h2>
<p>In Section <span class="math inline">\(5.13\)</span> we introduced the <span class="math inline">\(F\)</span> test for exclusion restrictions in the normal regression model. In this section we generalize this test to a broader set of restrictions. Let <span class="math inline">\(B_{0} \subset \mathbb{R}^{k}\)</span> be a constrained parameter space which imposes <span class="math inline">\(q\)</span> restrictions on <span class="math inline">\(\beta\)</span>.</p>
<p>Let <span class="math inline">\(\widehat{\beta}_{\text {ols }}\)</span> be the unrestricted least squares estimator and let <span class="math inline">\(\widehat{\sigma}^{2}=n^{-1} \sum_{i=1}^{n}\left(Y_{i}-X_{i}^{\prime} \widehat{\beta}_{\text {ols }}\right)^{2}\)</span> be the associated estimator of <span class="math inline">\(\sigma^{2}\)</span>. Let <span class="math inline">\(\widetilde{\beta}_{\text {cls }}\)</span> be the CLS estimator (9.11) satisfying <span class="math inline">\(\widetilde{\beta}_{\text {cls }} \in B_{0}\)</span> and let <span class="math inline">\(\widetilde{\sigma}^{2}=n^{-1} \sum_{i=1}^{n}\left(Y_{i}-X_{i}^{\prime} \widetilde{\beta}_{\text {cls }}\right)^{2}\)</span> be the associated estimator of <span class="math inline">\(\sigma^{2}\)</span>. The <span class="math inline">\(F\)</span> statistic for testing <span class="math inline">\(\mathbb{M}_{0}: \beta \in B_{0}\)</span> is</p>
<p><span class="math display">\[
F=\frac{\left(\tilde{\sigma}^{2}-\widehat{\sigma}^{2}\right) / q}{\widehat{\sigma}^{2} /(n-k)} .
\]</span></p>
<p>We can alternatively write</p>
<p><span class="math display">\[
F=\frac{\operatorname{SSE}\left(\widetilde{\beta}_{\mathrm{cls}}\right)-\operatorname{SSE}\left(\widehat{\beta}_{\mathrm{ols}}\right)}{q s^{2}}
\]</span></p>
<p>where <span class="math inline">\(\operatorname{SSE}(\beta)=\sum_{i=1}^{n}\left(Y_{i}-X_{i}^{\prime} \beta\right)^{2}\)</span> is the sum-of-squared errors.</p>
<p>This shows that <span class="math inline">\(F\)</span> is a criterion-based statistic. Using (8.21) we can also write <span class="math inline">\(F=J^{0} / q\)</span>, so the <span class="math inline">\(F\)</span> statistic is identical to the homoskedastic minimum distance statistic divided by the number of restrictions <span class="math inline">\(q\)</span>.</p>
<p>As we discussed in the previous section, in the special case of linear hypotheses <span class="math inline">\(\mathbb{M}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0}, J^{0}=\)</span> <span class="math inline">\(W^{0}\)</span>. It follows that in this case <span class="math inline">\(F=W^{0} / q\)</span>. Thus for linear restrictions the <span class="math inline">\(F\)</span> statistic equals the homoskedastic Wald statistic divided by <span class="math inline">\(q\)</span>. It follows that they are equivalent tests for <span class="math inline">\(\mathbb{H}_{0}\)</span> against <span class="math inline">\(\mathbb{H}_{1}\)</span>. Theorem 9.6 For tests of linear hypotheses <span class="math inline">\(\mathbb{H}_{0}: \boldsymbol{R}^{\prime} \beta=\theta_{0} \in \mathbb{R}^{q}\)</span>, the <span class="math inline">\(\mathrm{F}\)</span> statistic equals <span class="math inline">\(F=W^{0} / q\)</span> where <span class="math inline">\(W^{0}\)</span> is the homoskedastic Wald statistic. Thus under 7.2, <span class="math inline">\(\mathbb{E}\left[e^{2} \mid X\right]=\sigma^{2}&gt;0\)</span>, and <span class="math inline">\(\mathbb{M}_{0}: \theta=\theta_{0}\)</span>, then <span class="math inline">\(F \underset{d}{\longrightarrow} \chi_{q}^{2} / q\)</span>.</p>
<p>When using an <span class="math inline">\(F\)</span> statistic it is conventional to use the <span class="math inline">\(F_{q, n-k}\)</span> distribution for critical values and pvalues. Critical values are given in MATLAB by <span class="math inline">\(f\)</span> inv <span class="math inline">\((1-\alpha, q, n-k)\)</span> and <span class="math inline">\(p\)</span>-values by <span class="math inline">\(1-f c d f(F, q, n-k)\)</span>. Alternatively, the <span class="math inline">\(\chi_{q}^{2} / q\)</span> distribution can be used, using chi2inv <span class="math inline">\((1-\alpha, q) / q\)</span> and <span class="math inline">\(1-\operatorname{chi} 2 c d f(F * q, q)\)</span>, respectively. Using the <span class="math inline">\(F_{q, n-k}\)</span> distribution is a prudent small sample adjustment which yields exact answers if the errors are normal and otherwise slightly increasing the critical values and p-values relative to the asymptotic approximation. Once again, if the sample size is small enough that the choice makes a difference then probably we shouldn’t be trusting the asymptotic approximation anyway!</p>
<p>An elegant feature about (9.12) or (9.13) is that they are directly computable from the standard output from two simple OLS regressions, as the sum of squared errors (or regression variance) is a typical printed output from statistical packages and is often reported in applied tables. Thus <span class="math inline">\(F\)</span> can be calculated by hand from standard reported statistics even if you don’t have the original data (or if you are sitting in a seminar and listening to a presentation!).</p>
<p>If you are presented with an <span class="math inline">\(F\)</span> statistic (or a Wald statistic, as you can just divide by <span class="math inline">\(q\)</span> ) but don’t have access to critical values, a useful rule of thumb is to know that for large <span class="math inline">\(n\)</span> the <span class="math inline">\(5 %\)</span> asymptotic critical value is decreasing as <span class="math inline">\(q\)</span> increases and is less than 2 for <span class="math inline">\(q \geq 7\)</span>.</p>
<p>A word of warning: In many statistical packages when an OLS regression is estimated an “F-statistic” is automatically reported even though no hypothesis test was requested. What the package is reporting is an <span class="math inline">\(F\)</span> statistic of the hypothesis that all slope coefficients <span class="math inline">\({ }^{1}\)</span> are zero. This was a popular statistic in the early days of econometric reporting when sample sizes were very small and researchers wanted to know if there was “any explanatory power” to their regression. This is rarely an issue today as sample sizes are typically sufficiently large that this <span class="math inline">\(F\)</span> statistic is nearly always highly significant. While there are special cases where this <span class="math inline">\(F\)</span> statistic is useful these cases are not typical. As a general rule there is no reason to report this <span class="math inline">\(F\)</span> statistic.</p>
</section>
<section id="hausman-tests" class="level2" data-number="9.15">
<h2 data-number="9.15" class="anchored" data-anchor-id="hausman-tests"><span class="header-section-number">9.15</span> Hausman Tests</h2>
<p>Hausman (1978) introduced a general idea about how to test a hypothesis <span class="math inline">\(\mathbb{M}_{0}\)</span>. If you have two estimators, one which is efficient under <span class="math inline">\(\mathbb{M}_{0}\)</span> but inconsistent under <span class="math inline">\(\mathbb{H}_{1}\)</span>, and another which is consistent under <span class="math inline">\(\mathbb{H}_{1}\)</span>, then construct a test as a quadratic form in the differences of the estimators. In the case of testing a hypothesis <span class="math inline">\(\mathbb{M}_{0}: r(\beta)=\theta_{0}\)</span> let <span class="math inline">\(\widehat{\beta}_{\text {ols }}\)</span> denote the unconstrained least squares estimator and let <span class="math inline">\(\widetilde{\beta}_{\text {emd }}\)</span> denote the efficient minimum distance estimator which imposes <span class="math inline">\(r(\beta)=\theta_{0}\)</span>. Both estimators are consistent under <span class="math inline">\(\mathbb{M}_{0}\)</span> but <span class="math inline">\(\widetilde{\beta}_{\mathrm{emd}}\)</span> is asymptotically efficient. Under <span class="math inline">\(\mathbb{H}_{1}, \widehat{\beta}_{\mathrm{ols}}\)</span> is consistent for <span class="math inline">\(\beta\)</span> but <span class="math inline">\(\widetilde{\beta}_{\mathrm{emd}}\)</span> is inconsistent. The difference has the asymptotic distribution</p>
<p><span class="math display">\[
\sqrt{n}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right) \underset{d}{\longrightarrow} \mathrm{N}\left(0, \boldsymbol{V}_{\beta} \boldsymbol{R}\left(\boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta} \boldsymbol{R}\right)^{-1} \boldsymbol{R}^{\prime} \boldsymbol{V}_{\beta}\right) .
\]</span></p>
<p>Let <span class="math inline">\(\boldsymbol{A}^{-}\)</span>denote the Moore-Penrose generalized inverse. The Hausman statistic for <span class="math inline">\(\mathbb{H}_{0}\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H=\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime} \widehat{\operatorname{avar}}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right)^{-}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right) \\
&amp; =n\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime}\left(\widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta}\right)^{-}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right) .
\end{aligned}
\]</span></p>
<p><span class="math inline">\({ }^{1}\)</span> All coefficients except the intercept. The matrix <span class="math inline">\(\widehat{\boldsymbol{V}}_{\beta}^{1 / 2} \widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta}^{1 / 2}\)</span> idempotent so its generalized inverse is itself. (See Section A.11.) It follows that</p>
<p><span class="math display">\[
\begin{aligned}
&amp; =\widehat{\boldsymbol{V}}_{\beta}^{-1 / 2} \widehat{\boldsymbol{V}}_{\beta}^{1 / 2} \widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta}^{1 / 2} \widehat{\boldsymbol{V}}_{\beta}^{-1 / 2} \\
&amp; =\widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime} .
\end{aligned}
\]</span></p>
<p>Thus the Hausman statistic is</p>
<p><span class="math display">\[
H=n\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime} \widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right) .
\]</span></p>
<p>In the context of linear restrictions, <span class="math inline">\(\widehat{\boldsymbol{R}}=\boldsymbol{R}\)</span> and <span class="math inline">\(\boldsymbol{R}^{\prime} \widetilde{\beta}=\theta_{0}\)</span> so the statistic takes the form</p>
<p><span class="math display">\[
H=n\left(\boldsymbol{R}^{\prime} \widehat{\beta}_{\mathrm{ols}}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{R}}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}_{\mathrm{ols}}-\theta_{0}\right),
\]</span></p>
<p>which is precisely the Wald statistic. With nonlinear restrictions <span class="math inline">\(W\)</span> and <span class="math inline">\(H\)</span> can differ.</p>
<p>In either case we see that that the asymptotic null distribution of the Hausman statistic <span class="math inline">\(H\)</span> is <span class="math inline">\(\chi_{q}^{2}\)</span>, so the appropriate test is to reject <span class="math inline">\(\mathbb{M}_{0}\)</span> in favor of <span class="math inline">\(\mathbb{H}_{1}\)</span> if <span class="math inline">\(H&gt;c\)</span> where <span class="math inline">\(c\)</span> is a critical value taken from the <span class="math inline">\(\chi_{q}^{2}\)</span> distribution.</p>
<p>Theorem 9.7 For general hypotheses the Hausman test statistic is</p>
<p><span class="math display">\[
H=n\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right)^{\prime} \widehat{\boldsymbol{R}}\left(\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\beta} \widehat{\boldsymbol{R}}\right)^{-1} \widehat{\boldsymbol{R}}^{\prime}\left(\widehat{\beta}_{\mathrm{ols}}-\widetilde{\beta}_{\mathrm{emd}}\right) .
\]</span></p>
<p>Under Assumptions <span class="math inline">\(7.2,7.3,7.4\)</span>, and <span class="math inline">\(\mathbb{M}_{0}: r(\beta)=\theta_{0} \in \mathbb{R}^{q}, H \underset{d}{\longrightarrow} \chi_{q}^{2}\)</span></p>
</section>
<section id="score-tests" class="level2" data-number="9.16">
<h2 data-number="9.16" class="anchored" data-anchor-id="score-tests"><span class="header-section-number">9.16</span> Score Tests</h2>
<p>Score tests are traditionally derived in likelihood analysis but can more generally be constructed from first-order conditions evaluated at restricted estimates. We focus on the likelihood derivation.</p>
<p>Given the log likelihood function <span class="math inline">\(\ell_{n}\left(\beta, \sigma^{2}\right)\)</span>, a restriction <span class="math inline">\(\mathbb{H}_{0}: r(\beta)=\theta_{0}\)</span>, and restricted estimators <span class="math inline">\(\widetilde{\beta}\)</span> and <span class="math inline">\(\widetilde{\sigma}^{2}\)</span>, the score statistic for <span class="math inline">\(\mathbb{H}_{0}\)</span> is defined as</p>
<p><span class="math display">\[
S=\left(\frac{\partial}{\partial \beta} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right)\right)^{\prime}\left(-\frac{\partial^{2}}{\partial \beta \partial \beta^{\prime}} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right)\right)^{-1}\left(\frac{\partial}{\partial \beta} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right)\right) .
\]</span></p>
<p>The idea is that if the restriction is true then the restricted estimators should be close to the maximum of the log-likelihood where the derivative is zero. However if the restriction is false then the restricted estimators should be distant from the maximum and the derivative should be large. Hence small values of <span class="math inline">\(S\)</span> are expected under <span class="math inline">\(\mathbb{H}_{0}\)</span> and large values under <span class="math inline">\(\mathbb{H}_{1}\)</span>. Tests of <span class="math inline">\(\mathbb{M}_{0}\)</span> reject for large values of <span class="math inline">\(S\)</span>.</p>
<p>We explore the score statistic in the context of the normal regression model and linear hypotheses <span class="math inline">\(r(\beta)=\boldsymbol{R}^{\prime} \beta\)</span>. Recall that in the normal regression log-likelihood function is</p>
<p><span class="math display">\[
\ell_{n}\left(\beta, \sigma^{2}\right)=-\frac{n}{2} \log \left(2 \pi \sigma^{2}\right)-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(Y_{i}-X_{i}^{\prime} \beta\right)^{2} .
\]</span></p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-16.jpg" class="img-fluid"></p>
<p>The constrained MLE under linear hypotheses is constrained least squares</p>
<p><span class="math display">\[
\begin{aligned}
\widetilde{\beta} &amp;=\widehat{\beta}-\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{R}\left[\boldsymbol{R}^{\prime}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{R}\right]^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\boldsymbol{c}\right) \\
\widetilde{e}_{i} &amp;=Y_{i}-X_{i}^{\prime} \widetilde{\beta} \\
\widetilde{\sigma}^{2} &amp;=\frac{1}{n} \sum_{i=1}^{n} \widetilde{e}_{i}^{2}
\end{aligned}
\]</span></p>
<p>We can calculate that the derivative and Hessian are</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial}{\partial \beta} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right) &amp;=\frac{1}{\widetilde{\sigma}^{2}} \sum_{i=1}^{n} X_{i}\left(Y_{i}-X_{i}^{\prime} \widetilde{\beta}\right)=\frac{1}{\widetilde{\sigma}^{2}} \boldsymbol{X}^{\prime} \widetilde{\boldsymbol{e}} \\
-\frac{\partial^{2}}{\partial \beta \partial \beta^{\prime}} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right) &amp;=\frac{1}{\widetilde{\sigma}^{2}} \sum_{i=1}^{n} X_{i} X_{i}^{\prime}=\frac{1}{\widetilde{\sigma}^{2}} \boldsymbol{X}^{\prime} \boldsymbol{X}
\end{aligned}
\]</span></p>
<p>Since <span class="math inline">\(\widetilde{\boldsymbol{e}}=\boldsymbol{Y}-\boldsymbol{X} \widetilde{\beta}\)</span> we can further calculate that</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial}{\partial \beta} \ell_{n}\left(\widetilde{\beta}, \widetilde{\sigma}^{2}\right) &amp;=\frac{1}{\widetilde{\sigma}^{2}}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)\left(\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{Y}-\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{X} \widetilde{\beta}\right) \\
&amp;=\frac{1}{\widetilde{\sigma}^{2}}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)(\widehat{\beta}-\widetilde{\beta}) \\
&amp;=\frac{1}{\widetilde{\sigma}^{2}} \boldsymbol{R}\left[\boldsymbol{R}^{\prime}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{R}\right]^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\beta}-\boldsymbol{c}\right) .
\end{aligned}
\]</span></p>
<p>Together we find that</p>
<p><span class="math display">\[
S=\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{\beta}}-\boldsymbol{c}\right)^{\prime}\left(\boldsymbol{R}^{\prime}\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1} \boldsymbol{R}\right)^{-1}\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{\beta}}-\boldsymbol{c}\right) / \widetilde{\sigma}^{2} .
\]</span></p>
<p>This is identical to the homoskedastic Wald statistic with <span class="math inline">\(s^{2}\)</span> replaced by <span class="math inline">\(\widetilde{\sigma}^{2}\)</span>. We can also write <span class="math inline">\(S\)</span> as a monotonic transformation of the <span class="math inline">\(F\)</span> statistic, as</p>
<p><span class="math display">\[
S=n \frac{\left(\widetilde{\sigma}^{2}-\widehat{\sigma}^{2}\right)}{\widetilde{\sigma}^{2}}=n\left(1-\frac{\widehat{\sigma}^{2}}{\widetilde{\sigma}^{2}}\right)=n\left(1-\frac{1}{1+\frac{q}{n-k} F}\right) .
\]</span></p>
<p>The test “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> for large values of <span class="math inline">\(S\)</span>” is identical to the test “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> for large values of <span class="math inline">\(F\)</span>” so they are identical tests. Since for the normal regression model the exact distribution of <span class="math inline">\(F\)</span> is known, it is better to use the <span class="math inline">\(F\)</span> statistic with <span class="math inline">\(F\)</span> p-values.</p>
<p>In more complicated settings a potential advantage of score tests is that they are calculated using the restricted parameter estimates <span class="math inline">\(\widetilde{\beta}\)</span> rather than the unrestricted estimates <span class="math inline">\(\widehat{\beta}\)</span>. Thus when <span class="math inline">\(\widetilde{\beta}\)</span> is relatively easy to calculate there can be a preference for score statistics. This is not a concern for linear restrictions.</p>
<p>More generally, score and score-like statistics can be constructed from first-order conditions evaluated at restricted parameter estimates. Also, when test statistics are constructed using covariance matrix estimators which are calculated using restricted parameter estimates (e.g.&nbsp;restricted residuals) then these are often described as score tests.</p>
<p>An example of the latter is the Wald-type statistic</p>
<p><span class="math display">\[
W=\left(r(\widehat{\beta})-\theta_{0}\right)^{\prime}\left(\widehat{\boldsymbol{R}}^{\prime} \widetilde{\boldsymbol{V}}_{\widehat{\beta}} \widehat{\boldsymbol{R}}\right)^{-1}\left(r(\widehat{\beta})-\theta_{0}\right)
\]</span></p>
<p>where the covariance matrix estimate <span class="math inline">\(\widetilde{\boldsymbol{V}}_{\widehat{\beta}}\)</span> is calculated using the restricted residuals <span class="math inline">\(\widetilde{e}_{i}=Y_{i}-X_{i}^{\prime} \widetilde{\beta}\)</span>. This may be a good choice when <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\theta\)</span> are high-dimensional as in this context there may be worry that the estimator <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\beta}}\)</span> is imprecise.</p>
</section>
<section id="problems-with-tests-of-nonlinear-hypotheses" class="level2" data-number="9.17">
<h2 data-number="9.17" class="anchored" data-anchor-id="problems-with-tests-of-nonlinear-hypotheses"><span class="header-section-number">9.17</span> Problems with Tests of Nonlinear Hypotheses</h2>
<p>While the <span class="math inline">\(t\)</span> and Wald tests work well when the hypothesis is a linear restriction on <span class="math inline">\(\beta\)</span>, they can work quite poorly when the restrictions are nonlinear. This can be seen by a simple example introduced by Lafontaine and White (1986). Take the model <span class="math inline">\(Y \sim \mathrm{N}\left(\beta, \sigma^{2}\right.\)</span> ) and consider the hypothesis <span class="math inline">\(\mathbb{H}_{0}: \beta=1\)</span>. Let <span class="math inline">\(\widehat{\beta}\)</span> and <span class="math inline">\(\widehat{\sigma}^{2}\)</span> be the sample mean and variance of <span class="math inline">\(Y\)</span>. The standard Wald statistic to test <span class="math inline">\(\mathbb{H}_{0}\)</span> is</p>
<p><span class="math display">\[
W=n \frac{(\widehat{\beta}-1)^{2}}{\widehat{\sigma}^{2}} .
\]</span></p>
<p>Notice that <span class="math inline">\(\mathbb{M}_{0}\)</span> is equivalent to the hypothesis <span class="math inline">\(\mathbb{M}_{0}(s): \beta^{s}=1\)</span> for any positive integer <span class="math inline">\(s\)</span>. Letting <span class="math inline">\(r(\beta)=\)</span> <span class="math inline">\(\beta^{s}\)</span>, and noting <span class="math inline">\(\boldsymbol{R}=s \beta^{s-1}\)</span>, we find that the Wald statistic to test <span class="math inline">\(\mathbb{M}_{0}(s)\)</span> is</p>
<p><span class="math display">\[
W_{s}=n \frac{\left(\widehat{\beta}^{s}-1\right)^{2}}{\widehat{\sigma}^{2} s^{2} \widehat{\beta}^{2 s-2}} .
\]</span></p>
<p>While the hypothesis <span class="math inline">\(\beta^{s}=1\)</span> is unaffected by the choice of <span class="math inline">\(s\)</span>, the statistic <span class="math inline">\(W_{s}\)</span> varies with <span class="math inline">\(s\)</span>. This is an unfortunate feature of the Wald statistic.</p>
<p>To demonstrate this effect, we have plotted in Figure <span class="math inline">\(9.2\)</span> the Wald statistic <span class="math inline">\(W_{s}\)</span> as a function of <span class="math inline">\(s\)</span>, setting <span class="math inline">\(n / \widehat{\sigma}^{2}=10\)</span>. The increasing line is for the case <span class="math inline">\(\widehat{\beta}=0.8\)</span>. The decreasing line is for the case <span class="math inline">\(\widehat{\beta}=1.6\)</span>. It is easy to see that in each case there are values of <span class="math inline">\(s\)</span> for which the test statistic is significant relative to asymptotic critical values, while there are other values of <span class="math inline">\(s\)</span> for which the test statistic is insignificant. This is distressing because the choice of <span class="math inline">\(s\)</span> is arbitrary and irrelevant to the actual hypothesis.</p>
<p>Our first-order asymptotic theory is not useful to help pick <span class="math inline">\(s\)</span>, as <span class="math inline">\(W_{s} \underset{d}{\longrightarrow} \chi_{1}^{2}\)</span> under <span class="math inline">\(\mathbb{H}_{0}\)</span> for any <span class="math inline">\(s\)</span>. This is a context where Monte Carlo simulation can be quite useful as a tool to study and compare the exact distributions of statistical procedures in finite samples. The method uses random simulation to create artificial datasets to which we apply the statistical tools of interest. This produces random draws from the statistic’s sampling distribution. Through repetition, features of this distribution can be calculated.</p>
<p>In the present context of the Wald statistic, one feature of importance is the Type I error of the test using the asymptotic <span class="math inline">\(5 %\)</span> critical value <span class="math inline">\(3.84\)</span> - the probability of a false rejection, <span class="math inline">\(\mathbb{P}\left[W_{s}&gt;3.84 \mid \beta=1\right]\)</span>. Given the simplicity of the model this probability depends only on <span class="math inline">\(s, n\)</span>, and <span class="math inline">\(\sigma^{2}\)</span>. In Table <span class="math inline">\(9.2\)</span> we report the results of a Monte Carlo simulation where we vary these three parameters. The value of <span class="math inline">\(s\)</span> is varied from 1 to <span class="math inline">\(10, n\)</span> is varied among 20,100 , and 500 , and <span class="math inline">\(\sigma\)</span> is varied among 1 and 3 . The table reports the simulation estimate of the Type I error probability from 50,000 random samples. Each row of the table corresponds to a different value of <span class="math inline">\(s\)</span> - and thus corresponds to a particular choice of test statistic. The second through seventh columns contain the Type I error probabilities for different combinations of <span class="math inline">\(n\)</span> and <span class="math inline">\(\sigma\)</span>. These probabilities are calculated as the percentage of the 50,000 simulated Wald statistics <span class="math inline">\(W_{s}\)</span> which are larger than 3.84. The null hypothesis <span class="math inline">\(\beta^{s}=1\)</span> is true so these probabilities are Type I error.</p>
<p>To interpret the table remember that the ideal Type I error probability is <span class="math inline">\(5 %(.05)\)</span> with deviations indicating distortion. Type I error rates between <span class="math inline">\(3 %\)</span> and <span class="math inline">\(8 %\)</span> are considered reasonable. Error rates above <span class="math inline">\(10 %\)</span> are considered excessive. Rates above <span class="math inline">\(20 %\)</span> are unacceptable. When comparing statistical procedures we compare the rates row by row, looking for tests for which rejection rates are close to <span class="math inline">\(5 %\)</span> and rarely fall outside of the <span class="math inline">\(3 %-8 %\)</span> range. For this particular example the only test which meets this criterion is the conventional <span class="math inline">\(W=W_{1}\)</span> test. Any other <span class="math inline">\(s\)</span> leads to a test with unacceptable Type I error probabilities.</p>
<p>In Table <span class="math inline">\(9.2\)</span> you can also see the impact of variation in sample size. In each case the Type I error probability improves towards <span class="math inline">\(5 %\)</span> as the sample size <span class="math inline">\(n\)</span> increases. There is, however, no magic choice of <span class="math inline">\(n\)</span> for which all tests perform uniformly well. Test performance deteriorates as <span class="math inline">\(s\)</span> increases which is not surprising given the dependence of <span class="math inline">\(W_{s}\)</span> on <span class="math inline">\(s\)</span> as shown in Figure 9.2.</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-19.jpg" class="img-fluid"></p>
<p>Figure 9.2: Wald Statistic as a Function of <span class="math inline">\(s\)</span></p>
<p>In this example it is not surprising that the choice <span class="math inline">\(s=1\)</span> yields the best test statistic. Other choices are arbitrary and would not be used in practice. While this is clear in this particular example, in other examples natural choices are not obvious and the best choices may be counter-intuitive.</p>
<p>This point can be illustrated through an example based on Gregory and Veall (1985). Take the model</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;=\beta_{0}+X_{1} \beta_{1}+X_{2} \beta_{2}+e \\
\mathbb{E}[X e] &amp;=0
\end{aligned}
\]</span></p>
<p>and the hypothesis <span class="math inline">\(\mathbb{M}_{0}: \frac{\beta_{1}}{\beta_{2}}=\theta_{0}\)</span> where <span class="math inline">\(\theta_{0}\)</span> is a known constant. Equivalently, define <span class="math inline">\(\theta=\beta_{1} / \beta_{2}\)</span> so the hypothesis can be stated as <span class="math inline">\(\mathbb{M}_{0}: \theta=\theta_{0}\)</span>.</p>
<p>Let <span class="math inline">\(\widehat{\beta}=\left(\widehat{\beta}_{0}, \widehat{\beta}_{1}, \widehat{\beta}_{2}\right)\)</span> be the least squares estimator of <span class="math inline">\((9.14)\)</span>, let <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\beta}}\)</span> be an estimator of the covariance matrix for <span class="math inline">\(\widehat{\beta}\)</span> and set <span class="math inline">\(\widehat{\theta}=\widehat{\beta}_{1} / \widehat{\beta}_{2}\)</span>. Define</p>
<p><span class="math display">\[
\widehat{\boldsymbol{R}}_{1}=\left(\begin{array}{c}
0 \\
\frac{1}{\widehat{\beta}_{2}} \\
-\frac{\widehat{\beta}_{1}}{\widehat{\beta}_{2}^{2}}
\end{array}\right)
\]</span></p>
<p>Table 9.2: Type I Error Probability of Asymptotic <span class="math inline">\(5 % W(s)\)</span> Test</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-20.jpg" class="img-fluid"></p>
<p>Rejection frequencies from 50,000 simulated random samples.</p>
<p>so that the standard error for <span class="math inline">\(\widehat{\theta}\)</span> is <span class="math inline">\(s(\widehat{\theta})=\left(\widehat{\boldsymbol{R}}_{1}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \widehat{\boldsymbol{R}}_{1}\right)^{1 / 2}\)</span>. In this case a t-statistic for <span class="math inline">\(\mathbb{M}_{0}\)</span> is</p>
<p><span class="math display">\[
T_{1}=\frac{\left(\frac{\widehat{\beta}_{1}}{\widehat{\beta}_{2}}-\theta_{0}\right)}{s(\widehat{\theta})} .
\]</span></p>
<p>An alternative statistic can be constructed through reformulating the null hypothesis as</p>
<p><span class="math display">\[
\mathbb{M}_{0}: \beta_{1}-\theta_{0} \beta_{2}=0 .
\]</span></p>
<p>A t-statistic based on this formulation of the hypothesis is</p>
<p><span class="math display">\[
T_{2}=\frac{\widehat{\beta}_{1}-\theta_{0} \widehat{\beta}_{2}}{\left(\boldsymbol{R}_{2}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \boldsymbol{R}_{2}\right)^{1 / 2}}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\boldsymbol{R}_{2}=\left(\begin{array}{c}
0 \\
1 \\
-\theta_{0}
\end{array}\right) \text {. }
\]</span></p>
<p>To compare <span class="math inline">\(T_{1}\)</span> and <span class="math inline">\(T_{2}\)</span> we perform another simple Monte Carlo simulation. We let <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> be mutually independent <span class="math inline">\(\mathrm{N}(0,1)\)</span> variables, <span class="math inline">\(e\)</span> be an independent <span class="math inline">\(\mathrm{N}\left(0, \sigma^{2}\right)\)</span> draw with <span class="math inline">\(\sigma=3\)</span>, and normalize <span class="math inline">\(\beta_{0}=0\)</span> and <span class="math inline">\(\beta_{1}=1\)</span>. This leaves <span class="math inline">\(\beta_{2}\)</span> as a free parameter along with sample size <span class="math inline">\(n\)</span>. We vary <span class="math inline">\(\beta_{2}\)</span> among <span class="math inline">\(0.1\)</span>, <span class="math inline">\(0.25,0.50,0.75\)</span>, and <span class="math inline">\(1.0\)</span> and <span class="math inline">\(n\)</span> among 100 and 500 .</p>
<p>The one-sided Type I error probabilities <span class="math inline">\(\mathbb{P}[T&lt;-1.645]\)</span> and <span class="math inline">\(\mathbb{P}[T&gt;1.645]\)</span> are calculated from 50,000 simulated samples. The results are presented in Table 9.3. Ideally, the entries in the table should be <span class="math inline">\(0.05\)</span>. However, the rejection rates for the <span class="math inline">\(T_{1}\)</span> statistic diverge greatly from this value, especially for small values of <span class="math inline">\(\beta_{2}\)</span>. The left tail probabilities <span class="math inline">\(\mathbb{P}\left[T_{1}&lt;-1.645\right]\)</span> greatly exceed <span class="math inline">\(5 %\)</span>, while the right tail probabilities <span class="math inline">\(\mathbb{P}\left[T_{1}&gt;1.645\right]\)</span> are close to zero in most cases. In contrast, the rejection rates for the <span class="math inline">\(T_{2}\)</span> statistic are invariant to the value of <span class="math inline">\(\beta_{2}\)</span> and equal <span class="math inline">\(5 %\)</span> for both sample sizes. The implication of Table <span class="math inline">\(9.3\)</span> is that the two t-ratios have dramatically different sampling behavior.</p>
<p>The common message from both examples is that Wald statistics are sensitive to the algebraic formulation of the null hypothesis. Table 9.3: Type I Error Probability of Asymptotic 5% t-tests</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-21.jpg" class="img-fluid"></p>
<p>Rejection frequencies from 50,000 simulated random samples.</p>
<p>A simple solution is to use the minimum distance statistic <span class="math inline">\(J\)</span> which equals <span class="math inline">\(W\)</span> with <span class="math inline">\(r=1\)</span> in the first example, and <span class="math inline">\(\left|T_{2}\right|\)</span> in the second example. The minimum distance statistic is invariant to the algebraic formulation of the null hypothesis so is immune to this problem. Whenever possible, the Wald statistic should not be used to test nonlinear hypotheses.</p>
<p>Theoretical investigations of these issues include Park and Phillips (1988) and Dufour (1997).</p>
</section>
<section id="monte-carlo-simulation" class="level2" data-number="9.18">
<h2 data-number="9.18" class="anchored" data-anchor-id="monte-carlo-simulation"><span class="header-section-number">9.18</span> Monte Carlo Simulation</h2>
<p>In Section <span class="math inline">\(9.17\)</span> we introduced the method of Monte Carlo simulation to illustrate the small sample problems with tests of nonlinear hypotheses. In this section we describe the method in more detail.</p>
<p>Recall, our data consist of observations <span class="math inline">\(\left(Y_{i}, X_{i}\right)\)</span> which are random draws from a population distribution <span class="math inline">\(F\)</span>. Let <span class="math inline">\(\theta\)</span> be a parameter and let <span class="math inline">\(T=T\left(\left(Y_{1}, X_{1}\right), \ldots,\left(Y_{n}, X_{n}\right), \theta\right)\)</span> be a statistic of interest, for example an estimator <span class="math inline">\(\widehat{\theta}\)</span> or a t-statistic <span class="math inline">\((\widehat{\theta}-\theta) / s(\widehat{\theta})\)</span>. The exact distribution of <span class="math inline">\(T\)</span> is</p>
<p><span class="math display">\[
G(u, F)=\mathbb{P}[T \leq u \mid F] .
\]</span></p>
<p>While the asymptotic distribution of <span class="math inline">\(T\)</span> might be known, the exact (finite sample) distribution <span class="math inline">\(G\)</span> is generally unknown.</p>
<p>Monte Carlo simulation uses numerical simulation to compute <span class="math inline">\(G(u, F)\)</span> for selected choices of <span class="math inline">\(F\)</span>. This is useful to investigate the performance of the statistic <span class="math inline">\(T\)</span> in reasonable situations and sample sizes. The basic idea is that for any given <span class="math inline">\(F\)</span> the distribution function <span class="math inline">\(G(u, F)\)</span> can be calculated numerically through simulation. The name Monte Carlo derives from the Mediterranean gambling resort where games of chance are played.</p>
<p>The method of Monte Carlo is simple to describe. The researcher chooses <span class="math inline">\(F\)</span> (the distribution of the pseudo data) and the sample size <span class="math inline">\(n\)</span>. A “true” value of <span class="math inline">\(\theta\)</span> is implied by this choice, or equivalently the value <span class="math inline">\(\theta\)</span> is selected directly by the researcher which implies restrictions on <span class="math inline">\(F\)</span>.</p>
<p>Then the following experiment is conducted by computer simulation:</p>
<ol type="1">
<li><p><span class="math inline">\(n\)</span> independent random pairs <span class="math inline">\(\left(Y_{i}^{*}, X_{i}^{*}\right), i=1, \ldots, n\)</span>, are drawn from the distribution <span class="math inline">\(F\)</span> using the computer’s random number generator.</p></li>
<li><p>The statistic <span class="math inline">\(T=T\left(\left(Y_{1}^{*}, X_{1}^{*}\right), \ldots,\left(Y_{n}^{*}, X_{n}^{*}\right), \theta\right)\)</span> is calculated on this pseudo data.</p></li>
</ol>
<p>For step 1, computer packages have built-in random number procedures including <span class="math inline">\(U[0,1]\)</span> and <span class="math inline">\(N(0,1)\)</span>. From these most random variables can be constructed. (For example, a chi-square can be generated by sums of squares of normals.) For step 2, it is important that the statistic be evaluated at the “true” value of <span class="math inline">\(\theta\)</span> corresponding to the choice of <span class="math inline">\(F\)</span>.</p>
<p>The above experiment creates one random draw <span class="math inline">\(T\)</span> from the distribution <span class="math inline">\(G(u, F)\)</span>. This is one observation from an unknown distribution. Clearly, from one observation very little can be said. So the researcher repeats the experiment <span class="math inline">\(B\)</span> times where <span class="math inline">\(B\)</span> is a large number. Typically, we set <span class="math inline">\(B \geq 1000\)</span>. We will discuss this choice later.</p>
<p>Notationally, let the <span class="math inline">\(b^{t h}\)</span> experiment result in the draw <span class="math inline">\(T_{b}, b=1, \ldots, B\)</span>. These results are stored. After all <span class="math inline">\(B\)</span> experiments have been calculated these results constitute a random sample of size <span class="math inline">\(B\)</span> from the distribution of <span class="math inline">\(G(u, F)=\mathbb{P}\left[T_{b} \leq u\right]=\mathbb{P}[T \leq u \mid F]\)</span>.</p>
<p>From a random sample we can estimate any feature of interest using (typically) a method of moments estimator. We now describe some specific examples.</p>
<p>Suppose we are interested in the bias, mean-squared error (MSE), and/or variance of the distribution of <span class="math inline">\(\widehat{\theta}-\theta\)</span>. We then set <span class="math inline">\(T=\widehat{\theta}-\theta\)</span>, run the above experiment, and calculate</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\operatorname{bias}}[\widehat{\theta}] &amp;=\frac{1}{B} \sum_{b=1}^{B} T_{b}=\frac{1}{B} \sum_{b=1}^{B} \widehat{\theta}_{b}-\theta \\
\widehat{\operatorname{mse}}[\widehat{\theta}] &amp;=\frac{1}{B} \sum_{b=1}^{B}\left(T_{b}\right)^{2}=\frac{1}{B} \sum_{b=1}^{B}\left(\widehat{\theta}_{b}-\theta\right)^{2} \\
\widehat{\operatorname{var}}[\widehat{\theta}] &amp;=\widehat{\operatorname{mse}}[\widehat{\theta}]-(\widehat{\operatorname{bias}}[\hat{\theta}])^{2}
\end{aligned}
\]</span></p>
<p>Suppose we are interested in the Type I error associated with an asymptotic 5% two-sided t-test. We would then set <span class="math inline">\(T=|\widehat{\theta}-\theta| / s(\widehat{\theta})\)</span> and calculate</p>
<p><span class="math display">\[
\widehat{P}=\frac{1}{B} \sum_{b=1}^{B} \mathbb{1}\left\{T_{b} \geq 1.96\right\},
\]</span></p>
<p>the percentage of the simulated t-ratios which exceed the asymptotic <span class="math inline">\(5 %\)</span> critical value.</p>
<p>Suppose we are interested in the <span class="math inline">\(5 %\)</span> and <span class="math inline">\(95 %\)</span> quantile of <span class="math inline">\(T=\widehat{\theta}\)</span> or <span class="math inline">\(T=(\widehat{\theta}-\theta) / s(\widehat{\theta})\)</span>. We then compute the <span class="math inline">\(5 %\)</span> and <span class="math inline">\(95 %\)</span> sample quantiles of the sample <span class="math inline">\(\left\{T_{b}\right\}\)</span>. For details on quantile estimation see Section <span class="math inline">\(11.13\)</span> of Probability and Statistics for Economists.</p>
<p>The typical purpose of a Monte Carlo simulation is to investigate the performance of a statistical procedure in realistic settings. Generally, the performance will depend on <span class="math inline">\(n\)</span> and <span class="math inline">\(F\)</span>. In many cases an estimator or test may perform wonderfully for some values and poorly for others. It is therefore useful to conduct a variety of experiments for a selection of choices of <span class="math inline">\(n\)</span> and <span class="math inline">\(F\)</span>.</p>
<p>As discussed above the researcher must select the number of experiments <span class="math inline">\(B\)</span>. Often this is called the number of replications. Quite simply, a larger <span class="math inline">\(B\)</span> results in more precise estimates of the features of interest of <span class="math inline">\(G\)</span> but requires more computational time. In practice, therefore, the choice of <span class="math inline">\(B\)</span> is often guided by the computational demands of the statistical procedure. Since the results of a Monte Carlo experiment are estimates computed from a random sample of size <span class="math inline">\(B\)</span> it is straightforward to calculate standard errors for any quantity of interest. If the standard error is too large to make a reliable inference then <span class="math inline">\(B\)</span> will have to be increased. A useful rule-of-thumb is to set <span class="math inline">\(B=10,000\)</span> whenever possible.</p>
<p>In particular, it is simple to make inferences about rejection probabilities from statistical tests, such as the percentage estimate reported in (9.15). The random variable <span class="math inline">\(\mathbb{1}\left\{T_{b} \geq 1.96\right\}\)</span> is i.i.d. Bernoulli, equalling 1 with probability <span class="math inline">\(p=\mathbb{E}\left[\mathbb{1}\left\{T_{b} \geq 1.96\right\}\right]\)</span>. The average (9.15) is therefore an unbiased estimator of <span class="math inline">\(p\)</span> with standard error <span class="math inline">\(s(\widehat{p})=\sqrt{p(1-p) / B}\)</span>. As <span class="math inline">\(p\)</span> is unknown, this may be approximated by replacing <span class="math inline">\(p\)</span> with <span class="math inline">\(\widehat{p}\)</span> or with an hypothesized value. For example, if we are assessing an asymptotic <span class="math inline">\(5 %\)</span> test, then we can set <span class="math inline">\(s(\widehat{p})=\sqrt{(.05)(.95) / B} \simeq .22 / \sqrt{B}\)</span>. Hence, standard errors for <span class="math inline">\(B=100,1000\)</span>, and 5000, are, respectively, <span class="math inline">\(s(\widehat{p})=.022, .007\)</span>, and <span class="math inline">\(.003 .\)</span> Most papers in econometric methods and some empirical papers include the results of Monte Carlo simulations to illustrate the performance of their methods. When extending existing results it is good practice to start by replicating existing (published) results. This may not be exactly possible in the case of simulation results as they are inherently random. For example suppose a paper investigates a statistical test and reports a simulated rejection probability of <span class="math inline">\(0.07\)</span> based on a simulation with <span class="math inline">\(B=100\)</span> replications. Suppose you attempt to replicate this result and find a rejection probability of <span class="math inline">\(0.03\)</span> (again using <span class="math inline">\(B=100\)</span> simulation replications). Should you conclude that you have failed in your attempt? Absolutely not! Under the hypothesis that both simulations are identical you have two independent estimates, <span class="math inline">\(\widehat{p}_{1}=0.07\)</span> and <span class="math inline">\(\widehat{p}_{2}=0.03\)</span>, of a common probability <span class="math inline">\(p\)</span>. The asymptotic (as <span class="math inline">\(B \rightarrow \infty\)</span> ) distribution of their difference is <span class="math inline">\(\sqrt{B}\left(\widehat{p}_{1}-\widehat{p}_{2}\right) \underset{d}{\longrightarrow} \mathrm{N}(0,2 p(1-p))\)</span>, so a standard error for <span class="math inline">\(\widehat{p}_{1}-\widehat{p}_{2}=0.04\)</span> is <span class="math inline">\(\widehat{s}=\sqrt{2 \bar{p}(1-\bar{p}) / B} \simeq 0.03\)</span>, using the estimate <span class="math inline">\(\bar{p}=\left(\widehat{p}_{1}+\widehat{p}_{2}\right) / 2\)</span>. Since the t-ratio <span class="math inline">\(0.04 / 0.03=1.3\)</span> is not statistically significant it is incorrect to reject the null hypothesis that the two simulations are identical. The difference between the results <span class="math inline">\(\widehat{p}_{1}=0.07\)</span> and <span class="math inline">\(\widehat{p}_{2}=0.03\)</span> is consistent with random variation.</p>
<p>What should be done? The first mistake was to copy the previous paper’s choice of <span class="math inline">\(B=100\)</span>. Instead, suppose you set <span class="math inline">\(B=10,000\)</span> and now obtain <span class="math inline">\(\widehat{p}_{2}=0.04\)</span>. Then <span class="math inline">\(\widehat{p}_{1}-\widehat{p}_{2}=0.03\)</span> and a standard error is <span class="math inline">\(\widehat{s}=\)</span> <span class="math inline">\(\sqrt{\bar{p}(1-\bar{p})(1 / 100+1 / 10000)} \simeq 0.02\)</span>. Still we cannot reject the hypothesis that the two simulations are different. Even though the estimates ( <span class="math inline">\(0.07\)</span> and <span class="math inline">\(0.04)\)</span> appear to be quite different, the difficulty is that the original simulation used a very small number of replications <span class="math inline">\((B=100)\)</span> so the reported estimate is quite imprecise. In this case it is appropriate to conclude that your results “replicate” the previous study as there is no statistical evidence to reject the hypothesis that they are equivalent.</p>
<p>Most journals have policies requiring authors to make available their data sets and computer programs required for empirical results. Most do not have similar policies regarding simulations. Nevertheless, it is good professional practice to make your simulations available. The best practice is to post your simulation code on your webpage. This invites others to build on and use your results, leading to possible collaboration, citation, and/or advancement.</p>
</section>
<section id="confidence-intervals-by-test-inversion" class="level2" data-number="9.19">
<h2 data-number="9.19" class="anchored" data-anchor-id="confidence-intervals-by-test-inversion"><span class="header-section-number">9.19</span> Confidence Intervals by Test Inversion</h2>
<p>There is a close relationship between hypothesis tests and confidence intervals. We observed in Section <span class="math inline">\(7.13\)</span> that the standard <span class="math inline">\(95 %\)</span> asymptotic confidence interval for a parameter <span class="math inline">\(\theta\)</span> is</p>
<p><span class="math display">\[
\widehat{C}=[\widehat{\theta}-1.96 \times s(\widehat{\theta}), \quad \widehat{\theta}+1.96 \times s(\widehat{\theta})]=\{\theta:|T(\theta)| \leq 1.96\} .
\]</span></p>
<p>That is, we can describe <span class="math inline">\(\widehat{C}\)</span> as “The point estimate plus or minus 2 standard errors” or “The set of parameter values not rejected by a two-sided t-test.” The second definition, known as test statistic inversion, is a general method for finding confidence intervals, and typically produces confidence intervals with excellent properties.</p>
<p>Given a test statistic <span class="math inline">\(T(\theta)\)</span> and critical value <span class="math inline">\(c\)</span>, the acceptance region “Accept if <span class="math inline">\(T(\theta) \leq c\)</span>” is identical to the confidence interval <span class="math inline">\(\widehat{C}=\{\theta: T(\theta) \leq c\}\)</span>. Since the regions are identical the probability of coverage <span class="math inline">\(\mathbb{P}[\theta \in \widehat{C}]\)</span> equals the probability of correct acceptance <span class="math inline">\(\mathbb{P}[\)</span> Accept <span class="math inline">\(\mid \theta]\)</span> which is exactly 1 minus the Type I error probability. Thus inverting a test with good Type I error probabilities yields a confidence interval with good coverage probabilities.</p>
<p>Now suppose that the parameter of interest <span class="math inline">\(\theta=r(\beta)\)</span> is a nonlinear function of the coefficient vector <span class="math inline">\(\beta\)</span>. In this case the standard confidence interval for <span class="math inline">\(\theta\)</span> is the set <span class="math inline">\(\widehat{C}\)</span> as in (9.16) where <span class="math inline">\(\widehat{\theta}=r(\widehat{\beta})\)</span> is the point estimator and <span class="math inline">\(s(\widehat{\theta})=\sqrt{\widehat{\boldsymbol{R}}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \widehat{\boldsymbol{R}}}\)</span> is the delta method standard error. This confidence interval is inverting the t-test based on the nonlinear hypothesis <span class="math inline">\(r(\beta)=\theta\)</span>. The trouble is that in Section <span class="math inline">\(9.17\)</span> we learned that there is no unique t-statistic for tests of nonlinear hypotheses and that the choice of parameterization matters greatly. For example, if <span class="math inline">\(\theta=\beta_{1} / \beta_{2}\)</span> then the coverage probability of the standard interval (9.16) is 1 minus the probability of the Type I error, which as shown in Table <span class="math inline">\(8.2\)</span> can be far from the nominal <span class="math inline">\(5 %\)</span>.</p>
<p>In this example a good solution is the same as discussed in Section <span class="math inline">\(9.17\)</span> - to rewrite the hypothesis as a linear restriction. The hypothesis <span class="math inline">\(\theta=\beta_{1} / \beta_{2}\)</span> is the same as <span class="math inline">\(\theta \beta_{2}=\beta_{1}\)</span>. The t-statistic for this restriction is</p>
<p><span class="math display">\[
T(\theta)=\frac{\widehat{\beta}_{1}-\widehat{\beta}_{2} \theta}{\left(\boldsymbol{R}^{\prime} \widehat{\boldsymbol{V}}_{\widehat{\beta}} \boldsymbol{R}\right)^{1 / 2}}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\boldsymbol{R}=\left(\begin{array}{c}
1 \\
-\theta
\end{array}\right)
\]</span></p>
<p>and <span class="math inline">\(\widehat{V}_{\widehat{\beta}}\)</span> is the covariance matrix for <span class="math inline">\(\left(\widehat{\beta}_{1} \widehat{\beta}_{2}\right)\)</span>. A 95% confidence interval for <span class="math inline">\(\theta=\beta_{1} / \beta_{2}\)</span> is the set of values of <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(|T(\theta)| \leq 1.96\)</span>. Since <span class="math inline">\(T(\theta)\)</span> is a nonlinear function of <span class="math inline">\(\theta\)</span> one method to find the confidence set is grid search over <span class="math inline">\(\theta\)</span>.</p>
<p>For example, in the wage equation</p>
<p><span class="math display">\[
\log (\text { wage })=\beta_{1} \text { experience }+\beta_{2} \text { experience }^{2} / 100+\cdots
\]</span></p>
<p>the highest expected wage occurs at experience <span class="math inline">\(=-50 \beta_{1} / \beta_{2}\)</span>. From Table <span class="math inline">\(4.1\)</span> we have the point estimate <span class="math inline">\(\widehat{\theta}=29.8\)</span> and we can calculate the standard error <span class="math inline">\(s(\widehat{\theta})=0.022\)</span> for a 95% confidence interval <span class="math inline">\([29.8,29.9]\)</span>. However, if we instead invert the linear form of the test we numerically find the interval <span class="math inline">\([29.1,30.6]\)</span> which is much larger. From the evidence presented in Section <span class="math inline">\(9.17\)</span> we know the first interval can be quite inaccurate and the second interval is greatly preferred.</p>
</section>
<section id="multiple-tests-and-bonferroni-corrections" class="level2" data-number="9.20">
<h2 data-number="9.20" class="anchored" data-anchor-id="multiple-tests-and-bonferroni-corrections"><span class="header-section-number">9.20</span> Multiple Tests and Bonferroni Corrections</h2>
<p>In most applications economists examine a large number of estimates, test statistics, and p-values. What does it mean (or does it mean anything) if one statistic appears to be “significant” after examining a large number of statistics? This is known as the problem of multiple testing or multiple comparisons.</p>
<p>To be specific, suppose we examine a set of <span class="math inline">\(k\)</span> coefficients, standard errors and t-ratios, and consider the “significance” of each statistic. Based on conventional reasoning, for each coefficient we would reject the hypothesis that the coefficient is zero with asymptotic size <span class="math inline">\(\alpha\)</span> if the absolute t-statistic exceeds the <span class="math inline">\(1-\alpha\)</span> critical value of the normal distribution, or equivalently if the <span class="math inline">\(\mathrm{p}\)</span>-value for the t-statistic is smaller than <span class="math inline">\(\alpha\)</span>. If we observe that one of the <span class="math inline">\(k\)</span> statistics is “significant” based on this criterion, that means that one of the p-values is smaller than <span class="math inline">\(\alpha\)</span>, or equivalently, that the smallest p-value is smaller than <span class="math inline">\(\alpha\)</span>. We can then rephrase the question: Under the joint hypothesis that a set of <span class="math inline">\(k\)</span> hypotheses are all true, what is the probability that the smallest <span class="math inline">\(\mathrm{p}\)</span>-value is smaller than <span class="math inline">\(\alpha\)</span> ? In general, we cannot provide a precise answer to this quesion, but the Bonferroni correction bounds this probability by <span class="math inline">\(\alpha k\)</span>. The Bonferroni method furthermore suggests that if we want the familywise error probability (the probability that one of the tests falsely rejects) to be bounded below <span class="math inline">\(\alpha\)</span>, then an appropriate rule is to reject only if the smallest p-value is smaller than <span class="math inline">\(\alpha / k\)</span>. Equivalently, the Bonferroni familywise <span class="math inline">\(\mathrm{p}\)</span>-value is <span class="math inline">\(k \min _{j \leq k} p_{j}\)</span>.</p>
<p>Formally, suppose we have <span class="math inline">\(k\)</span> hypotheses <span class="math inline">\(\mathbb{M}_{j}, j=1, \ldots, k\)</span>. For each we have a test and associated pvalue <span class="math inline">\(p_{j}\)</span> with the property that when <span class="math inline">\(\mathbb{H}_{j}\)</span> is true <span class="math inline">\(\lim _{n \rightarrow \infty} \mathbb{P}\left[p_{j}&lt;\alpha\right]=\alpha\)</span>. We then observe that among the <span class="math inline">\(k\)</span> tests, one of the <span class="math inline">\(k\)</span> is “significant” if <span class="math inline">\(\min _{j \leq k} p_{j}&lt;\alpha\)</span>. This event can be written as</p>
<p><span class="math display">\[
\left\{\min _{j \leq k} p_{j}&lt;\alpha\right\}=\bigcup_{j=1}^{k}\left\{p_{j}&lt;\alpha\right\} .
\]</span></p>
<p>Boole’s inequality states that for any <span class="math inline">\(k\)</span> events <span class="math inline">\(A_{j}, \mathbb{P}\left[\bigcup_{j=1}^{k} A_{j}\right] \leq \sum_{j=1}^{k} \mathbb{P}\left[A_{k}\right]\)</span>. Thus</p>
<p><span class="math display">\[
\mathbb{P}\left[\min _{j \leq k} p_{j}&lt;\alpha\right] \leq \sum_{j=1}^{k} \mathbb{P}\left[p_{j}&lt;\alpha\right] \rightarrow k \alpha
\]</span></p>
<p>as stated. This demonstates that the asymptotic familywise rejection probability is at most <span class="math inline">\(k\)</span> times the individual rejection probability.</p>
<p>Furthermore,</p>
<p><span class="math display">\[
\mathbb{P}\left[\min _{j \leq k} p_{j}&lt;\frac{\alpha}{k}\right] \leq \sum_{j=1}^{k} \mathbb{P}\left[p_{j}&lt;\frac{\alpha}{k}\right] \rightarrow \alpha .
\]</span></p>
<p>This demonstrates that the asymptotic familywise rejection probability can be controlled (bounded below <span class="math inline">\(\alpha\)</span> ) if each individual test is subjected to the stricter standard that a p-value must be smaller than <span class="math inline">\(\alpha / k\)</span> to be labeled as “significant”.</p>
<p>To illustrate, suppose we have two coefficient estimates with individual p-values <span class="math inline">\(0.04\)</span> and <span class="math inline">\(0.15\)</span>. Based on a conventional <span class="math inline">\(5 %\)</span> level the standard individual tests would suggest that the first coefficient estimate is “significant” but not the second. A Bonferroni 5% test, however, does not reject as it would require that the smallest p-value be smaller than <span class="math inline">\(0.025\)</span>, which is not the case in this example. Alternatively, the Bonferroni familywise <span class="math inline">\(\mathrm{p}\)</span>-value is <span class="math inline">\(0.04 \times 2=0.08\)</span>, which is not significant at the <span class="math inline">\(5 %\)</span> level.</p>
<p>In contrast, if the two p-values were <span class="math inline">\(0.01\)</span> and <span class="math inline">\(0.15\)</span>, then the Bonferroni familywise p-value would be <span class="math inline">\(0.01 \times 2=0.02\)</span>, which is significant at the <span class="math inline">\(5 %\)</span> level.</p>
</section>
<section id="power-and-test-consistency" class="level2" data-number="9.21">
<h2 data-number="9.21" class="anchored" data-anchor-id="power-and-test-consistency"><span class="header-section-number">9.21</span> Power and Test Consistency</h2>
<p>The power of a test is the probability of rejecting <span class="math inline">\(\mathbb{M}_{0}\)</span> when <span class="math inline">\(\mathbb{M}_{1}\)</span> is true.</p>
<p>For simplicity suppose that <span class="math inline">\(Y_{i}\)</span> is i.i.d. <span class="math inline">\(\mathrm{N}\left(\theta, \sigma^{2}\right)\)</span> with <span class="math inline">\(\sigma^{2}\)</span> known, consider the t-statistic <span class="math inline">\(T(\theta)=\sqrt{n}(\bar{Y}-\theta) / \sigma\)</span>, and tests of <span class="math inline">\(\mathbb{M}_{0}: \theta=0\)</span> against <span class="math inline">\(\mathbb{M}_{1}: \theta&gt;0\)</span>. We reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(T=T(0)&gt;c\)</span>. Note that</p>
<p><span class="math display">\[
T=T(\theta)+\sqrt{n} \theta / \sigma
\]</span></p>
<p>and <span class="math inline">\(T(\theta)\)</span> has an exact <span class="math inline">\(\mathrm{N}(0,1)\)</span> distribution. This is because <span class="math inline">\(T(\theta)\)</span> is centered at the true mean <span class="math inline">\(\theta\)</span>, while the test statistic <span class="math inline">\(T(0)\)</span> is centered at the (false) hypothesized mean of 0 .</p>
<p>The power of the test is</p>
<p><span class="math display">\[
\mathbb{P}[T&gt;c \mid \theta]=\mathbb{P}[\mathrm{Z}+\sqrt{n} \theta / \sigma&gt;c]=1-\Phi(c-\sqrt{n} \theta / \sigma) .
\]</span></p>
<p>This function is monotonically increasing in <span class="math inline">\(\mu\)</span> and <span class="math inline">\(n\)</span>, and decreasing in <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(c\)</span>.</p>
<p>Notice that for any <span class="math inline">\(c\)</span> and <span class="math inline">\(\theta \neq 0\)</span> the power increases to 1 as <span class="math inline">\(n \rightarrow \infty\)</span>. This means that for <span class="math inline">\(\theta \in \mathbb{H}_{1}\)</span> the test will reject <span class="math inline">\(\mathbb{M}_{0}\)</span> with probability approaching 1 as the sample size gets large. We call this property test consistency.</p>
<p>Definition 9.3 A test of <span class="math inline">\(\mathbb{H}_{0}: \theta \in \Theta_{0}\)</span> is consistent against fixed alternatives if for all <span class="math inline">\(\theta \in \Theta_{1}, \mathbb{P}\left[\right.\)</span> Reject <span class="math inline">\(\left.\mathbb{M}_{0} \mid \theta\right] \rightarrow 1\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<p>For tests of the form “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(T&gt;c\)</span>”, a sufficient condition for test consistency is that the <span class="math inline">\(T\)</span> diverges to positive infinity with probability one for all <span class="math inline">\(\theta \in \Theta_{1}\)</span>. Definition 9.4 We say that <span class="math inline">\(T \underset{p}{\rightarrow}\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> if for all <span class="math inline">\(M&lt;\infty, \mathbb{P}[T \leq M] \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>. Similarly, we say that <span class="math inline">\(T \underset{p}{\rightarrow}-\infty\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> if for all <span class="math inline">\(M&lt;\infty\)</span>, <span class="math inline">\(\mathbb{P}[T \geq-M] \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span></p>
<p>In general, t-tests and Wald tests are consistent against fixed alternatives. Take a t-statistic for a test of <span class="math inline">\(\mathbb{\sharp}_{0}: \theta=\theta_{0}, T=\left(\widehat{\theta}-\theta_{0}\right) / s(\widehat{\theta})\)</span> where <span class="math inline">\(\theta_{0}\)</span> is a known value and <span class="math inline">\(s(\widehat{\theta})=\sqrt{n^{-1} \widehat{V}_{\theta}}\)</span>. Note that</p>
<p><span class="math display">\[
T=\frac{\widehat{\theta}-\theta}{s(\widehat{\theta})}+\frac{\sqrt{n}\left(\theta-\theta_{0}\right)}{\sqrt{\widehat{V}_{\theta}}} .
\]</span></p>
<p>The first term on the right-hand-side converges in distribution to <span class="math inline">\(\mathrm{N}(0,1)\)</span>. The second term on the righthand-side equals zero if <span class="math inline">\(\theta=\theta_{0}\)</span>, converges in probability to <span class="math inline">\(+\infty\)</span> if <span class="math inline">\(\theta&gt;\theta_{0}\)</span>, and converges in probability to <span class="math inline">\(-\infty\)</span> if <span class="math inline">\(\theta&lt;\theta_{0}\)</span>. Thus the two-sided t-test is consistent against <span class="math inline">\(\mathbb{M}_{1}: \theta \neq \theta_{0}\)</span>, and one-sided t-tests are consistent against the alternatives for which they are designed.</p>
<p>Theorem 9.8 Under Assumptions 7.2, 7.3, and 7.4, for <span class="math inline">\(\theta=r(\beta) \neq \theta_{0}\)</span> and <span class="math inline">\(q=1\)</span>, then <span class="math inline">\(|T| \underset{p}{\longrightarrow}\)</span>. For any <span class="math inline">\(c&lt;\infty\)</span> the test “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(|T|&gt;c\)</span>” is consistent against fixed alternatives.</p>
<p>The Wald statistic for <span class="math inline">\(\mathbb{M}_{0}: \theta=r(\beta)=\theta_{0}\)</span> against <span class="math inline">\(\mathbb{M}_{1}: \theta \neq \theta_{0}\)</span> is <span class="math inline">\(W=n\left(\widehat{\theta}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{V}}_{\theta}^{-1}\left(\widehat{\theta}-\theta_{0}\right)\)</span>. Under <span class="math inline">\(\mathbb{H}_{1}\)</span>, <span class="math inline">\(\widehat{\theta} \underset{p}{\longrightarrow} \theta \neq \theta_{0}\)</span>. Thus <span class="math inline">\(\left(\widehat{\theta}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{V}}_{\theta}^{-1}\left(\widehat{\theta}-\theta_{0}\right) \underset{p}{\longrightarrow}\left(\theta-\theta_{0}\right)^{\prime} \boldsymbol{V}_{\theta}^{-1}\left(\theta-\theta_{0}\right)&gt;0\)</span>. Hence under <span class="math inline">\(\mathbb{H}_{1}, W \underset{p}{\longrightarrow}\)</span>. Again, this implies that Wald tests are consistent.</p>
<p>Theorem 9.9 Under Assumptions 7.2, 7.3, and 7.4, for <span class="math inline">\(\theta=r(\beta) \neq \theta_{0}\)</span>, then <span class="math inline">\(W \underset{p}{\longrightarrow}\)</span>. For any <span class="math inline">\(c&lt;\infty\)</span> the test “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(W&gt;c\)</span>” is consistent against fixed alternatives.</p>
</section>
<section id="asymptotic-local-power" class="level2" data-number="9.22">
<h2 data-number="9.22" class="anchored" data-anchor-id="asymptotic-local-power"><span class="header-section-number">9.22</span> Asymptotic Local Power</h2>
<p>Consistency is a good property for a test but is does not provided a tool to calculate test power. To approximate the power function we need a distributional approximation.</p>
<p>The standard asymptotic method for power analysis uses what are called local alternatives. This is similar to our analysis of restriction estimation under misspecification (Section 8.13). The technique is to index the parameter by sample size so that the asymptotic distribution of the statistic is continuous in a localizing parameter. In this section we consider t-tests on real-valued parameters and in the next section Wald tests. Specifically, we consider parameter vectors <span class="math inline">\(\beta_{n}\)</span> which are indexed by sample size <span class="math inline">\(n\)</span> and satisfy the real-valued relationship</p>
<p><span class="math display">\[
\theta_{n}=r\left(\beta_{n}\right)=\theta_{0}+n^{-1 / 2} h
\]</span></p>
<p>where the scalar <span class="math inline">\(h\)</span> is called a localizing parameter. We index <span class="math inline">\(\beta_{n}\)</span> and <span class="math inline">\(\theta_{n}\)</span> by sample size to indicate their dependence on <span class="math inline">\(n\)</span>. The way to think of (9.17) is that the true value of the parameters are <span class="math inline">\(\beta_{n}\)</span> and <span class="math inline">\(\theta_{n}\)</span>. The parameter <span class="math inline">\(\theta_{n}\)</span> is close to the hypothesized value <span class="math inline">\(\theta_{0}\)</span>, with deviation <span class="math inline">\(n^{-1 / 2} h\)</span>.</p>
<p>The specification (9.17) states that for any fixed <span class="math inline">\(h, \theta_{n}\)</span> approaches <span class="math inline">\(\theta_{0}\)</span> as <span class="math inline">\(n\)</span> gets large. Thus <span class="math inline">\(\theta_{n}\)</span> is “close” or “local” to <span class="math inline">\(\theta_{0}\)</span>. The concept of a localizing sequence (9.17) might seem odd since in the actual world the sample size cannot mechanically affect the value of the parameter. Thus (9.17) should not be interpreted literally. Instead, it should be interpreted as a technical device which allows the asymptotic distribution to be continuous in the alternative hypothesis.</p>
<p>To evaluate the asymptotic distribution of the test statistic we start by examining the scaled estimator centered at the hypothesized value <span class="math inline">\(\theta_{0}\)</span>. Breaking it into a term centered at the true value <span class="math inline">\(\theta_{n}\)</span> and a remainder we find</p>
<p><span class="math display">\[
\sqrt{n}\left(\widehat{\theta}-\theta_{0}\right)=\sqrt{n}\left(\widehat{\theta}-\theta_{n}\right)+\sqrt{n}\left(\theta_{n}-\theta_{0}\right)=\sqrt{n}\left(\widehat{\theta}-\theta_{n}\right)+h
\]</span></p>
<p>where the second equality is (9.17). The first term is asymptotically normal:</p>
<p><span class="math display">\[
\sqrt{n}\left(\widehat{\theta}-\theta_{n}\right) \underset{d}{\longrightarrow} \sqrt{V_{\theta}} Z
\]</span></p>
<p>where <span class="math inline">\(Z \sim \mathrm{N}(0,1)\)</span>. Therefore</p>
<p><span class="math display">\[
\sqrt{n}\left(\widehat{\theta}-\theta_{0}\right) \underset{d}{\longrightarrow} \sqrt{V_{\theta}} Z+h \sim \mathrm{N}\left(h, V_{\theta}\right) .
\]</span></p>
<p>This asymptotic distribution depends continuously on the localizing parameter <span class="math inline">\(h\)</span>.</p>
<p>Applied to the <span class="math inline">\(t\)</span> statistic we find</p>
<p><span class="math display">\[
T=\frac{\widehat{\theta}-\theta_{0}}{s(\widehat{\theta})} \underset{d}{\longrightarrow} \frac{\sqrt{V_{\theta}} Z+h}{\sqrt{V_{\theta}}} \sim Z+\delta
\]</span></p>
<p>where <span class="math inline">\(\delta=h / \sqrt{V_{\theta}}\)</span>. This generalizes Theorem <span class="math inline">\(9.1\)</span> (which assumes <span class="math inline">\(\mathbb{M}_{0}\)</span> is true) to allow for local alternatives of the form (9.17).</p>
<p>Consider a t-test of <span class="math inline">\(\mathbb{M}_{0}\)</span> against the one-sided alternative <span class="math inline">\(\mathbb{M}_{1}: \theta&gt;\theta_{0}\)</span> which rejects <span class="math inline">\(\mathbb{H}_{0}\)</span> for <span class="math inline">\(T&gt;c\)</span> where <span class="math inline">\(\Phi(c)=1-\alpha\)</span>. The asymptotic local power of this test is the limit (as the sample size diverges) of the rejection probability under the local alternative (9.17)</p>
<p><span class="math display">\[
\begin{aligned}
\lim _{n \rightarrow \infty} \mathbb{P}\left[\text { Reject } \mathbb{M}_{0}\right] &amp;=\lim _{n \rightarrow \infty} \mathbb{P}[T&gt;c] \\
&amp;=\mathbb{P}[Z+\delta&gt;c] \\
&amp;=1-\Phi(c-\delta) \\
&amp;=\Phi(\delta-c) \\
&amp; \stackrel{\text { def }}{=} \pi(\delta) .
\end{aligned}
\]</span></p>
<p>We call <span class="math inline">\(\pi(\delta)\)</span> the asymptotic local power function.</p>
<p>In Figure 9.3(a) we plot the local power function <span class="math inline">\(\pi(\delta)\)</span> as a function of <span class="math inline">\(\delta \in[-1,4]\)</span> for tests of asymptotic size <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(\alpha=0.01 . \delta=0\)</span> corresponds to the null hypothesis so <span class="math inline">\(\pi(\delta)=\alpha\)</span>. The power functions are monotonically increasing in <span class="math inline">\(\delta\)</span>. Note that the power is lower than <span class="math inline">\(\alpha\)</span> for <span class="math inline">\(\delta&lt;0\)</span> due to the one-sided nature of the test.</p>
<p>We can see that the power functions are ranked by <span class="math inline">\(\alpha\)</span> so that the test with <span class="math inline">\(\alpha=0.05\)</span> has higher power than the test with <span class="math inline">\(\alpha=0.01\)</span>. This is the inherent trade-off between size and power. Decreasing size induces a decrease in power, and conversely.</p>
<p><img src="images//2022_09_17_d22774979aa7978900adg-28.jpg" class="img-fluid"></p>
<ol type="a">
<li>One-Sided t Test</li>
</ol>
<p><img src="images//2022_09_17_d22774979aa7978900adg-28(1).jpg" class="img-fluid"></p>
<ol start="2" type="a">
<li>Vector Case</li>
</ol>
<p>Figure 9.3: Asymptotic Local Power Function</p>
<p>The coefficient <span class="math inline">\(\delta\)</span> can be interpreted as the parameter deviation measured as a multiple of the standard error <span class="math inline">\(s(\widehat{\theta})\)</span>. To see this, recall that <span class="math inline">\(s(\widehat{\theta})=n^{-1 / 2} \sqrt{\widehat{V}_{\theta}} \simeq n^{-1 / 2} \sqrt{V_{\theta}}\)</span> and then note that</p>
<p><span class="math display">\[
\delta=\frac{h}{\sqrt{V_{\theta}}} \simeq \frac{n^{-1 / 2} h}{s(\widehat{\theta})}=\frac{\theta_{n}-\theta_{0}}{s(\widehat{\theta})} .
\]</span></p>
<p>Thus <span class="math inline">\(\delta\)</span> approximately equals the deviation <span class="math inline">\(\theta_{n}-\theta_{0}\)</span> expressed as multiples of the standard error <span class="math inline">\(s(\widehat{\theta})\)</span>. Thus as we examine Figure 9.3(a) we can interpret the power function at <span class="math inline">\(\delta=1\)</span> (e.g.&nbsp;<span class="math inline">\(26 %\)</span> for a 5% size test) as the power when the parameter <span class="math inline">\(\theta_{n}\)</span> is one standard error above the hypothesized value. For example, from Table <span class="math inline">\(4.2\)</span> the standard error for the coefficient on “Married Female” is <span class="math inline">\(0.010\)</span>. Thus, in this example <span class="math inline">\(\delta=1\)</span> corresponds to <span class="math inline">\(\theta_{n}=0.010\)</span> or an <span class="math inline">\(1.0 %\)</span> wage premium for married females. Our calculations show that the asymptotic power of a one-sided <span class="math inline">\(5 %\)</span> test against this alternative is about <span class="math inline">\(26 %\)</span>.</p>
<p>The difference between power functions can be measured either vertically or horizontally. For example, in Figure 9.3(a) there is a vertical dashed line at <span class="math inline">\(\delta=1\)</span>, showing that the asymptotic local power function <span class="math inline">\(\pi(\delta)\)</span> equals <span class="math inline">\(26 %\)</span> for <span class="math inline">\(\alpha=0.0\)</span>, and <span class="math inline">\(9 %\)</span> for <span class="math inline">\(\alpha=0.01\)</span>. This is the difference in power across tests of differing size, holding fixed the parameter in the alternative.</p>
<p>A horizontal comparison can also be illuminating. To illustrate, in Figure 9.3(a) there is a horizontal dashed line at <span class="math inline">\(50 %\)</span> power. <span class="math inline">\(50 %\)</span> power is a useful benchmark as it is the point where the test has equal odds of rejection and acceptance. The dotted line crosses the two power curves at <span class="math inline">\(\delta=1.65(\alpha=0.05)\)</span> and <span class="math inline">\(\delta=2.33(\alpha=0.01)\)</span>. This means that the parameter <span class="math inline">\(\theta\)</span> must be at least <span class="math inline">\(1.65\)</span> standard errors above the hypothesized value for a one-sided <span class="math inline">\(5 %\)</span> test to have <span class="math inline">\(50 %\)</span> (approximate) power, and <span class="math inline">\(2.33\)</span> standard errors for a one-sided <span class="math inline">\(1 %\)</span> test.</p>
<p>The ratio of these values (e.g.&nbsp;2.33/1.65 = 1.41) measures the relative parameter magnitude needed to achieve the same power. (Thus, for a <span class="math inline">\(1 %\)</span> size test to achieve <span class="math inline">\(50 %\)</span> power, the parameter must be <span class="math inline">\(41 %\)</span> larger than for a <span class="math inline">\(5 %\)</span> size test.) Even more interesting, the square of this ratio (e.g.&nbsp;<span class="math inline">\(1.41^{2}=2\)</span> ) is the increase in sample size needed to achieve the same power under fixed parameters. That is, to achieve <span class="math inline">\(50 %\)</span> power, a <span class="math inline">\(1 %\)</span> size test needs twice as many observations as a <span class="math inline">\(5 %\)</span> size test. This interpretation follows by the following informal argument. By definition and (9.17) <span class="math inline">\(\delta=h / \sqrt{V_{\theta}}=\sqrt{n}\left(\theta_{n}-\theta_{0}\right) / \sqrt{V_{\theta}}\)</span>. Thus holding <span class="math inline">\(\theta\)</span> and <span class="math inline">\(V_{\theta}\)</span> fixed, <span class="math inline">\(\delta^{2}\)</span> is proportional to <span class="math inline">\(n\)</span>.</p>
<p>The analysis of a two-sided t test is similar. (9.18) implies that</p>
<p><span class="math display">\[
T=\left|\frac{\widehat{\theta}-\theta_{0}}{s(\widehat{\theta})}\right| \vec{d}|Z+\delta|
\]</span></p>
<p>and thus the local power of a two-sided t test is</p>
<p><span class="math display">\[
\lim _{n \rightarrow \infty} \mathbb{P}\left[\text { Reject } \mathbb{H}_{0}\right]=\lim _{n \rightarrow \infty} \mathbb{P}[T&gt;c]=\mathbb{P}[|Z+\delta|&gt;c]=\Phi(\delta-c)+\Phi(-\delta-c)
\]</span></p>
<p>which is monotonically increasing in <span class="math inline">\(|\delta|\)</span>.</p>
<p>Theorem 9.10 Under Assumptions 7.2, 7.3,7.4, and <span class="math inline">\(\theta_{n}=r\left(\beta_{n}\right)=r_{0}+n^{-1 / 2} h\)</span>, then</p>
<p><span class="math display">\[
T\left(\theta_{0}\right)=\frac{\widehat{\theta}-\theta_{0}}{s(\widehat{\theta})} \underset{d}{\longrightarrow} Z+\delta
\]</span></p>
<p>where <span class="math inline">\(Z \sim \mathrm{N}(0,1)\)</span> and <span class="math inline">\(\delta=h / \sqrt{V_{\theta}}\)</span>. For <span class="math inline">\(c\)</span> such that <span class="math inline">\(\Phi(c)=1-\alpha\)</span>,</p>
<p><span class="math display">\[
\mathbb{P}\left[T\left(\theta_{0}\right)&gt;c\right] \longrightarrow \Phi(\delta-c) .
\]</span></p>
<p>Furthermore, for <span class="math inline">\(c\)</span> such that <span class="math inline">\(\Phi(c)=1-\alpha / 2\)</span>,</p>
<p><span class="math display">\[
\mathbb{P}\left[\left|T\left(\theta_{0}\right)\right|&gt;c\right] \longrightarrow \Phi(\delta-c)+\Phi(-\delta-c) .
\]</span></p>
</section>
<section id="asymptotic-local-power-vector-case" class="level2" data-number="9.23">
<h2 data-number="9.23" class="anchored" data-anchor-id="asymptotic-local-power-vector-case"><span class="header-section-number">9.23</span> Asymptotic Local Power, Vector Case</h2>
<p>In this section we extend the local power analysis of the previous section to the case of vector-valued alternatives. We generalize (9.17) to vector-valued <span class="math inline">\(\theta_{n}\)</span>. The local parameterization is</p>
<p><span class="math display">\[
\theta_{n}=r\left(\beta_{n}\right)=\theta_{0}+n^{-1 / 2} h
\]</span></p>
<p>where <span class="math inline">\(h\)</span> is <span class="math inline">\(q \times 1\)</span>.</p>
<p>Under (9.19),</p>
<p><span class="math display">\[
\sqrt{n}\left(\widehat{\theta}-\theta_{0}\right)=\sqrt{n}\left(\widehat{\theta}-\theta_{n}\right)+h \underset{d}{\longrightarrow} Z_{h} \sim \mathrm{N}\left(h, \boldsymbol{V}_{\theta}\right),
\]</span></p>
<p>a normal random vector with mean <span class="math inline">\(h\)</span> and covariance matrix <span class="math inline">\(\boldsymbol{V}_{\theta}\)</span>.</p>
<p>Applied to the Wald statistic we find</p>
<p><span class="math display">\[
W=n\left(\widehat{\theta}-\theta_{0}\right)^{\prime} \widehat{\boldsymbol{V}}_{\theta}^{-1}\left(\widehat{\theta}-\theta_{0}\right) \underset{d}{\longrightarrow} Z_{h}^{\prime} \boldsymbol{V}_{\theta}^{-1} Z_{h} \sim \chi_{q}^{2}(\lambda)
\]</span></p>
<p>where <span class="math inline">\(\lambda=h^{\prime} \boldsymbol{V}^{-1} h . \chi_{q}^{2}(\lambda)\)</span> is a non-central chi-square random variable with non-centrality parameter <span class="math inline">\(\lambda\)</span>. (Theorem 5.3.6.)</p>
<p>The convergence (9.20) shows that under the local alternatives (9.19), W <span class="math inline">\(\underset{d}{ } \chi_{q}^{2}(\lambda)\)</span>. This generalizes the null asymptotic distribution which obtains as the special case <span class="math inline">\(\lambda=0\)</span>. We can use this result to obtain a continuous asymptotic approximation to the power function. For any significance level <span class="math inline">\(\alpha&gt;0\)</span> set the asymptotic critical value <span class="math inline">\(c\)</span> so that <span class="math inline">\(\mathbb{P}\left[\chi_{q}^{2}&gt;c\right]=\alpha\)</span>. Then as <span class="math inline">\(n \rightarrow \infty\)</span>,</p>
<p><span class="math display">\[
\mathbb{P}[W&gt;c] \longrightarrow \mathbb{P}\left[\chi_{q}^{2}(\lambda)&gt;c\right] \stackrel{\text { def }}{=} \pi(\lambda) .
\]</span></p>
<p>The asymptotic local power function <span class="math inline">\(\pi(\lambda)\)</span> depends only on <span class="math inline">\(\alpha, q\)</span>, and <span class="math inline">\(\lambda\)</span>.</p>
<p>Theorem 9.11 Under Assumptions 7.2, 7.3, 7.4, and <span class="math inline">\(\theta_{n}=r\left(\beta_{n}\right)=\theta_{0}+n^{-1 / 2} h\)</span>, then <span class="math inline">\(W \underset{d}{\longrightarrow} \chi_{q}^{2}(\lambda)\)</span> where <span class="math inline">\(\lambda=h^{\prime} \boldsymbol{V}_{\theta}^{-1} h\)</span>. Furthermore, for <span class="math inline">\(c\)</span> such that <span class="math inline">\(\mathbb{P}\left[\chi_{q}^{2}&gt;c\right]=\)</span> <span class="math inline">\(\alpha, \mathbb{P}[W&gt;c] \longrightarrow \mathbb{P}\left[\chi_{q}^{2}(\lambda)&gt;c\right]\)</span></p>
<p>Figure 9.3(b) plots <span class="math inline">\(\pi(\lambda)\)</span> as a function of <span class="math inline">\(\lambda\)</span> for <span class="math inline">\(q=1, q=2\)</span>, and <span class="math inline">\(q=3\)</span>, and <span class="math inline">\(\alpha=0.05\)</span>. The asymptotic power functions are monotonically increasing in <span class="math inline">\(\lambda\)</span> and asymptote to one.</p>
<p>Figure 9.3(b) also shows the power loss for fixed non-centrality parameter <span class="math inline">\(\lambda\)</span> as the dimensionality of the test increases. The power curves shift to the right as <span class="math inline">\(q\)</span> increases, resulting in a decrease in power. This is illustrated by the dashed line at <span class="math inline">\(50 %\)</span> power. The dashed line crosses the three power curves at <span class="math inline">\(\lambda=3.85(q=1), \lambda=4.96(q=2)\)</span>, and <span class="math inline">\(\lambda=5.77(q=3)\)</span>. The ratio of these <span class="math inline">\(\lambda\)</span> values correspond to the relative sample sizes needed to obtain the same power. Thus increasing the dimension of the test from <span class="math inline">\(q=1\)</span> to <span class="math inline">\(q=2\)</span> requires a <span class="math inline">\(28 %\)</span> increase in sample size, or an increase from <span class="math inline">\(q=1\)</span> to <span class="math inline">\(q=3\)</span> requires a <span class="math inline">\(50 %\)</span> increase in sample size, to maintain <span class="math inline">\(50 %\)</span> power.</p>
</section>
<section id="exercises" class="level2" data-number="9.24">
<h2 data-number="9.24" class="anchored" data-anchor-id="exercises"><span class="header-section-number">9.24</span> Exercises</h2>
<p>Exercise 9.1 Prove that if an additional regressor <span class="math inline">\(\boldsymbol{X}_{k+1}\)</span> is added to <span class="math inline">\(\boldsymbol{X}\)</span>, Theil’s adjusted <span class="math inline">\(\bar{R}^{2}\)</span> increases if and only if <span class="math inline">\(\left|T_{k+1}\right|&gt;1\)</span>, where <span class="math inline">\(T_{k+1}=\widehat{\beta}_{k+1} / s\left(\widehat{\beta}_{k+1}\right)\)</span> is the t-ratio for <span class="math inline">\(\widehat{\beta}_{k+1}\)</span> and</p>
<p><span class="math display">\[
s\left(\widehat{\beta}_{k+1}\right)=\left(s^{2}\left[\left(\boldsymbol{X}^{\prime} \boldsymbol{X}\right)^{-1}\right]_{k+1, k+1}\right)^{1 / 2}
\]</span></p>
<p>is the homoskedasticity-formula standard error.</p>
<p>Exercise 9.2 You have two independent samples <span class="math inline">\(\left(Y_{1 i}, X_{1 i}\right)\)</span> and <span class="math inline">\(\left(Y_{2 i}, X_{2 i}\right)\)</span> both with sample sizes <span class="math inline">\(n\)</span> which satisfy <span class="math inline">\(Y_{1}=X_{1}^{\prime} \beta_{1}+e_{1}\)</span> and <span class="math inline">\(Y_{2}=X_{2}^{\prime} \beta_{2}+e_{2}\)</span>, where <span class="math inline">\(\mathbb{E}\left[X_{1} e_{1}\right]=0\)</span> and <span class="math inline">\(\mathbb{E}\left[X_{2} e_{2}\right]=0\)</span>. Let <span class="math inline">\(\widehat{\beta}_{1}\)</span> and <span class="math inline">\(\widehat{\beta}_{2}\)</span> be the OLS estimators of <span class="math inline">\(\beta_{1} \in \mathbb{R}^{k}\)</span> and <span class="math inline">\(\beta_{2} \in \mathbb{R}^{k}\)</span>.</p>
<ol type="a">
<li><p>Find the asymptotic distribution of <span class="math inline">\(\sqrt{n}\left(\left(\widehat{\beta}_{2}-\widehat{\beta}_{1}\right)-\left(\beta_{2}-\beta_{1}\right)\right)\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p></li>
<li><p>Find an appropriate test statistic for <span class="math inline">\(\mathbb{H}_{0}: \beta_{2}=\beta_{1}\)</span>.</p></li>
<li><p>Find the asymptotic distribution of this statistic under <span class="math inline">\(\mathbb{H}_{0}\)</span>.</p></li>
</ol>
<p>Exercise 9.3 Let <span class="math inline">\(T\)</span> be a t-statistic for <span class="math inline">\(\mathbb{H}_{0}: \theta=0\)</span> versus <span class="math inline">\(\mathbb{H}_{1}: \theta \neq 0\)</span>. Since <span class="math inline">\(|T| \rightarrow{ }_{d}|Z|\)</span> under <span class="math inline">\(\mathbb{H}_{0}\)</span>, someone suggests the test “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(|T|&lt;c_{1}\)</span> or <span class="math inline">\(|T|&gt;c_{2}\)</span>, where <span class="math inline">\(c_{1}\)</span> is the <span class="math inline">\(\alpha / 2\)</span> quantile of <span class="math inline">\(|Z|\)</span> and <span class="math inline">\(c_{2}\)</span> is the <span class="math inline">\(1-\alpha / 2\)</span> quantile of <span class="math inline">\(|Z|\)</span>.</p>
<ol type="a">
<li>Show that the asymptotic size of the test is <span class="math inline">\(\alpha\)</span>. (b) Is this a good test of <span class="math inline">\(\mathbb{M}_{0}\)</span> versus <span class="math inline">\(\mathbb{M}_{1}\)</span> ? Why or why not?</li>
</ol>
<p>Exercise 9.4 Let <span class="math inline">\(W\)</span> be a Wald statistic for <span class="math inline">\(\mathbb{M}_{0}: \theta=0\)</span> versus <span class="math inline">\(\mathbb{M}_{1}: \theta \neq 0\)</span>, where <span class="math inline">\(\theta\)</span> is <span class="math inline">\(q \times 1\)</span>. Since <span class="math inline">\(W \underset{d}{\rightarrow} \chi_{q}^{2}\)</span> under <span class="math inline">\(H_{0}\)</span>, someone suggests the test “Reject <span class="math inline">\(\mathbb{H}_{0}\)</span> if <span class="math inline">\(W&lt;c_{1}\)</span> or <span class="math inline">\(W&gt;c_{2}\)</span>, where <span class="math inline">\(c_{1}\)</span> is the <span class="math inline">\(\alpha / 2\)</span> quantile of <span class="math inline">\(\chi_{q}^{2}\)</span> and <span class="math inline">\(c_{2}\)</span> is the <span class="math inline">\(1-\alpha / 2\)</span> quantile of <span class="math inline">\(\chi_{q}^{2}\)</span>.</p>
<ol type="a">
<li><p>Show that the asymptotic size of the test is <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p>Is this a good test of <span class="math inline">\(\mathbb{M}_{0}\)</span> versus <span class="math inline">\(\mathbb{H}_{1}\)</span> ? Why or why not?</p></li>
</ol>
<p>Exercise 9.5 Take the linear model <span class="math inline">\(Y=X_{1}^{\prime} \beta_{1}+X_{2}^{\prime} \beta_{2}+e\)</span> with <span class="math inline">\(\mathbb{E}[X e]=0\)</span> where both <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> are <span class="math inline">\(q \times 1\)</span>. Show how to test the hypotheses <span class="math inline">\(\mathbb{M}_{0}: \beta_{1}=\beta_{2}\)</span> against <span class="math inline">\(\mathbb{M}_{1}: \beta_{1} \neq \beta_{2}\)</span>.</p>
<p>Exercise 9.6 Suppose a researcher wants to know which of a set of 20 regressors has an effect on a variable testscore. He regresses testscore on the 20 regressors and reports the results. One of the 20 regressors (studytime) has a large t-ratio (about 2.5), while the other t-ratios are insignificant (smaller than 2 in absolute value). He argues that the data show that studytime is the key predictor for testscore. Do you agree with this conclusion? Is there a deficiency in his reasoning?</p>
<p>Exercise 9.7 Take the model <span class="math inline">\(Y=X \beta_{1}+X^{2} \beta_{2}+e\)</span> with <span class="math inline">\(\mathbb{E}[e \mid X]=0\)</span> where <span class="math inline">\(Y\)</span> is wages (dollars per hour) and <span class="math inline">\(X\)</span> is age. Describe how you would test the hypothesis that the expected wage for a 40 -year-old worker is <span class="math inline">\(\$ 20\)</span> an hour.</p>
<p>Exercise 9.8 You want to test <span class="math inline">\(\mathbb{H}_{0}: \beta_{2}=0\)</span> against <span class="math inline">\(\mathbb{H}_{1}: \beta_{2} \neq 0\)</span> in the model <span class="math inline">\(Y=X_{1}^{\prime} \beta_{1}+X_{2}^{\prime} \beta_{2}+e\)</span> with <span class="math inline">\(\mathbb{E}[X e]=0\)</span>. You read a paper which estimates the model</p>
<p><span class="math display">\[
Y=X_{1}^{\prime} \widehat{\gamma}_{1}+\left(X_{2}-X_{1}\right)^{\prime} \widehat{\gamma}_{2}+u
\]</span></p>
<p>and reports a test of <span class="math inline">\(\mathbb{M}_{0}: \gamma_{2}=0\)</span> against <span class="math inline">\(\mathbb{M}_{1}: \gamma_{2} \neq 0\)</span>. Is this related to the test you wanted to conduct?</p>
<p>Exercise 9.9 Suppose a researcher uses one dataset to test a specific hypothesis <span class="math inline">\(\mathbb{H}_{0}\)</span> against <span class="math inline">\(\mathbb{H}_{1}\)</span> and finds that he can reject <span class="math inline">\(\mathbb{H}_{0}\)</span>. A second researcher gathers a similar but independent dataset, uses similar methods and finds that she cannot reject <span class="math inline">\(\mathbb{M}_{0}\)</span>. How should we (as interested professionals) interpret these mixed results?</p>
<p>Exercise 9.10 In Exercise <span class="math inline">\(7.8\)</span> you showed that <span class="math inline">\(\sqrt{n}\left(\widehat{\sigma}^{2}-\sigma^{2}\right) \underset{d}{\rightarrow} \mathrm{N}(0, V)\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> for some <span class="math inline">\(V\)</span>. Let <span class="math inline">\(\widehat{V}\)</span> be an estimator of <span class="math inline">\(V\)</span>.</p>
<ol type="a">
<li><p>Using this result construct a t-statistic for <span class="math inline">\(\mathbb{H}_{0}: \sigma^{2}=1\)</span> against <span class="math inline">\(\mathbb{H}_{1}: \sigma^{2} \neq 1\)</span>.</p></li>
<li><p>Using the Delta Method find the asymptotic distribution of <span class="math inline">\(\sqrt{n}(\widehat{\sigma}-\sigma)\)</span>.</p></li>
<li><p>Use the previous result to construct a t-statistic for <span class="math inline">\(\mathbb{M}_{0}: \sigma=1\)</span> against <span class="math inline">\(\mathbb{H}_{1}: \sigma \neq 1\)</span>.</p></li>
<li><p>Are the null hypotheses in (a) and (c) the same or are they different? Are the tests in (a) and (c) the same or are they different? If they are different, describe a context in which the two tests would give contradictory results.</p></li>
</ol>
<p>Exercise 9.11 Consider a regression such as Table <span class="math inline">\(4.1\)</span> where both experience and its square are included. A researcher wants to test the hypothesis that experience does not affect mean wages and does this by computing the t-statistic for experience. Is this the correct approach? If not, what is the appropriate testing method? Exercise 9.12 A researcher estimates a regression and computes a test of <span class="math inline">\(\mathbb{H}_{0}\)</span> against <span class="math inline">\(\mathbb{H}_{1}\)</span> and finds a pvalue of <span class="math inline">\(p=0.08\)</span>, or “not significant”. She says “I need more data. If I had a larger sample the test will have more power and then the test will reject.” Is this interpretation correct?</p>
<p>Exercise 9.13 A common view is that “If the sample size is large enough, any hypothesis will be rejected.” What does this mean? Interpret and comment.</p>
<p>Exercise 9.14 Take the model <span class="math inline">\(Y=X^{\prime} \beta+e\)</span> with <span class="math inline">\(\mathbb{E}[X e]=0\)</span> and parameter of interest <span class="math inline">\(\theta=\boldsymbol{R}^{\prime} \beta\)</span> with <span class="math inline">\(\boldsymbol{R} k \times 1\)</span>. Let <span class="math inline">\(\widehat{\beta}\)</span> be the least squares estimator and <span class="math inline">\(\widehat{\boldsymbol{V}}_{\widehat{\beta}}\)</span> its variance estimator.</p>
<ol type="a">
<li><p>Write down <span class="math inline">\(\widehat{C}\)</span>, the <span class="math inline">\(95 %\)</span> asymptotic confidence interval for <span class="math inline">\(\theta\)</span>, in terms of <span class="math inline">\(\widehat{\beta}, \widehat{\boldsymbol{V}} \widehat{\widehat{\beta}}\)</span>, <span class="math inline">\(\boldsymbol{R}\)</span>, and <span class="math inline">\(z=1.96\)</span> (the <span class="math inline">\(97.5 %\)</span> quantile of <span class="math inline">\(N(0,1))\)</span>.</p></li>
<li><p>Show that the decision “Reject <span class="math inline">\(\mathbb{M}_{0}\)</span> if <span class="math inline">\(\theta_{0} \notin \widehat{C}\)</span>” is an asymptotic <span class="math inline">\(5 %\)</span> test of <span class="math inline">\(\mathbb{M}_{0}: \theta=\theta_{0}\)</span>.</p></li>
</ol>
<p>Exercise 9.15 You are at a seminar where a colleague presents a simulation study of a test of a hypothesis <span class="math inline">\(\mathbb{H}_{0}\)</span> with nominal size <span class="math inline">\(5 %\)</span>. Based on <span class="math inline">\(B=100\)</span> simulation replications under <span class="math inline">\(\mathbb{H}_{0}\)</span> the estimated size is <span class="math inline">\(7 %\)</span>. Your colleague says: “Unfortunately the test over-rejects.”</p>
<ol type="a">
<li><p>Do you agree or disagree with your colleague? Explain. Hint: Use an asymptotic (large B) approximation.</p></li>
<li><p>Suppose the number of simulation replications were <span class="math inline">\(B=1000\)</span> yet the estimated size is still <span class="math inline">\(7 %\)</span>. Does your answer change?</p></li>
</ol>
<p>Exercise 9.16 Consider two alternative regression models</p>
<p><span class="math display">\[
\begin{aligned}
Y &amp;=X_{1}^{\prime} \beta_{1}+e_{1} \\
\mathbb{E}\left[X_{1} e_{1}\right] &amp;=0 \\
Y &amp;=X_{2}^{\prime} \beta_{2}+e_{2} \\
\mathbb{E}\left[X_{2} e_{2}\right] &amp;=0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> have at least some different regressors. (For example, (9.21) is a wage regression on geographic variables and (2) is a wage regression on personal appearance measurements.) You want to know if model (9.21) or model (9.22) fits the data better. Define <span class="math inline">\(\sigma_{1}^{2}=\mathbb{E}\left[e_{1}^{2}\right]\)</span> and <span class="math inline">\(\sigma_{2}^{2}=\mathbb{E}\left[e_{2}^{2}\right]\)</span>. You decide that the model with the smaller variance fit (e.g., model (9.21) fits better if <span class="math inline">\(\sigma_{1}^{2}&lt;\sigma_{2}^{2}\)</span>.) You decide to test for this by testing the hypothesis of equal fit <span class="math inline">\(\mathbb{H}_{0}: \sigma_{1}^{2}=\sigma_{2}^{2}\)</span> against the alternative of unequal fit <span class="math inline">\(\mathbb{H}_{1}: \sigma_{1}^{2} \neq \sigma_{2}^{2}\)</span>. For simplicity, suppose that <span class="math inline">\(e_{1 i}\)</span> and <span class="math inline">\(e_{2 i}\)</span> are observed.</p>
<ol type="a">
<li><p>Construct an estimator <span class="math inline">\(\widehat{\theta}\)</span> of <span class="math inline">\(\theta=\sigma_{1}^{2}-\sigma_{2}^{2}\)</span>.</p></li>
<li><p>Find the asymptotic distribution of <span class="math inline">\(\sqrt{n}(\widehat{\theta}-\theta)\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p></li>
<li><p>Find an estimator of the asymptotic variance of <span class="math inline">\(\widehat{\theta}\)</span>.</p></li>
<li><p>Propose a test of asymptotic size <span class="math inline">\(\alpha\)</span> of <span class="math inline">\(\mathbb{M}_{0}\)</span> against <span class="math inline">\(\mathbb{M}_{1}\)</span>.</p></li>
<li><p>Suppose the test accepts <span class="math inline">\(\mathbb{M}_{0}\)</span>. Briefly, what is your interpretation? Exercise 9.17 You have two regressors <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> and estimate a regression with all quadratic terms included</p></li>
</ol>
<p><span class="math display">\[
Y=\alpha+\beta_{1} X_{1}+\beta_{2} X_{2}+\beta_{3} X_{1}^{2}+\beta_{4} X_{2}^{2}+\beta_{5} X_{1} X_{2}+e .
\]</span></p>
<p>One of your advisors asks: Can we exclude the variable <span class="math inline">\(X_{2}\)</span> from this regression?</p>
<p>How do you translate this question into a statistical test? When answering these questions, be specific, not general.</p>
<ol type="a">
<li><p>What is the relevant null and alternative hypotheses?</p></li>
<li><p>What is an appropriate test statistic?</p></li>
<li><p>What is the appropriate asymptotic distribution for the statistic?</p></li>
<li><p>What is the rule for acceptance/rejection of the null hypothesis?</p></li>
</ol>
<p>Exercise 9.18 The observed data is <span class="math inline">\(\left\{Y_{i}, X_{i}, Z_{i}\right\} \in \mathbb{R} \times \mathbb{R}^{k} \times \mathbb{R}^{\ell}, k&gt;1\)</span> and <span class="math inline">\(\ell&gt;1, i=1, \ldots, n\)</span>. An econometrician first estimates <span class="math inline">\(Y_{i}=X_{i}^{\prime} \widehat{\beta}+\widehat{e}_{i}\)</span> by least squares. The econometrician next regresses the residual <span class="math inline">\(\widehat{e}_{i}\)</span> on <span class="math inline">\(Z_{i}\)</span>, which can be written as <span class="math inline">\(\widehat{e}_{i}=Z_{i}^{\prime} \widetilde{\gamma}+\widetilde{u}_{i}\)</span>.</p>
<ol type="a">
<li><p>Define the population parameter <span class="math inline">\(\gamma\)</span> being estimated in this second regression.</p></li>
<li><p>Find the probability limit for <span class="math inline">\(\widetilde{\gamma}\)</span>.</p></li>
<li><p>Suppose the econometrician constructs a Wald statistic <span class="math inline">\(W\)</span> for <span class="math inline">\(\mathbb{H}_{0}: \gamma=0\)</span> from the second regression, ignoring the two-stage estimation process. Write down the formula for <span class="math inline">\(W\)</span>.</p></li>
<li><p>Assume <span class="math inline">\(\mathbb{E}\left[Z X^{\prime}\right]=0\)</span>. Find the asymptotic distribution for <span class="math inline">\(W\)</span> under <span class="math inline">\(\mathbb{M}_{0}: \gamma=0\)</span>.</p></li>
<li><p>If <span class="math inline">\(\mathbb{E}\left[Z X^{\prime}\right] \neq 0\)</span> will your answer to (d) change?</p></li>
</ol>
<p>Exercise 9.19 An economist estimates <span class="math inline">\(Y=X_{1}^{\prime} \beta_{1}+X_{2} \beta_{2}+e\)</span> by least squares and tests hypothesis <span class="math inline">\(\mathbb{H}_{0}: \beta_{2}=0\)</span> against <span class="math inline">\(\mathbb{H}_{1}: \beta_{2} \neq 0\)</span>. Assume <span class="math inline">\(\beta_{1} \in \mathbb{R}^{k}\)</span> and <span class="math inline">\(\beta_{2} \in \mathbb{R}\)</span>. She obtains a Wald statistic <span class="math inline">\(W=0.34\)</span>. The sample size is <span class="math inline">\(n=500\)</span>.</p>
<ol type="a">
<li><p>What is the correct degrees of freedom for the <span class="math inline">\(\chi^{2}\)</span> distribution to evaluate the significance of the Wald statistic?</p></li>
<li><p>The Wald statistic <span class="math inline">\(W\)</span> is very small. Indeed, is it less than the <span class="math inline">\(1 %\)</span> quantile of the appropriate <span class="math inline">\(\chi^{2}\)</span> distribution? If so, should you reject <span class="math inline">\(\mathbb{H}_{0}\)</span> ? Explain your reasoning.</p></li>
</ol>
<p>Exercise 9.20 You are reading a paper, and it reports the results from two nested OLS regressions:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;Y_{i}=X_{1 i}^{\prime} \widetilde{\beta}_{1}+\widetilde{e}_{i} \\
&amp;Y_{i}=X_{1 i}^{\prime} \widehat{\beta}_{1}+X_{2 i}^{\prime} \widehat{\beta}_{2}+\widehat{e}_{i} .
\end{aligned}
\]</span></p>
<p>Some summary statistics are reported:</p>
<p><span class="math display">\[
\begin{array}{ll}
\text { Short Regression } &amp; \text { Long Regression } \\
R^{2}=.20 &amp; R^{2}=.26 \\
\sum_{i=1}^{n} \widetilde{e}_{i}^{2}=106 &amp; \sum_{i=1}^{n} \widehat{e}_{i}^{2}=100 \\
\# \text { of coefficients }=5 &amp; \# \text { of coefficients }=8 \\
n=50 &amp; n=50
\end{array}
\]</span></p>
<p>You are curious if the estimate <span class="math inline">\(\widehat{\beta}_{2}\)</span> is statistically different from the zero vector. Is there a way to determine an answer from this information? Do you have to make any assumptions (beyond the standard regularity conditions) to justify your answer? Exercise 9.21 Take the model <span class="math inline">\(Y=X_{1} \beta_{1}+X_{2} \beta_{2}+X_{3} \beta_{3}+X_{4} \beta_{4}+e\)</span> with <span class="math inline">\(\mathbb{E}[X e]=0\)</span>. Describe how to test</p>
<p><span class="math display">\[
\mathbb{M}_{0}: \frac{\beta_{1}}{\beta_{2}}=\frac{\beta_{3}}{\beta_{4}}
\]</span></p>
<p>against</p>
<p><span class="math display">\[
\mathbb{M}_{1}: \frac{\beta_{1}}{\beta_{2}} \neq \frac{\beta_{3}}{\beta_{4}} .
\]</span></p>
<p>Exercise 9.22 You have a random sample from the model <span class="math inline">\(Y=X \beta_{1}+X^{2} \beta_{2}+e\)</span> with <span class="math inline">\(\mathbb{E}[e \mid X]=0\)</span> where <span class="math inline">\(Y\)</span> is wages (dollars per hour) and <span class="math inline">\(X\)</span> is age. Describe how you would test the hypothesis that the expected wage for a 40 -year-old worker is <span class="math inline">\(\$ 20\)</span> an hour.</p>
<p>Exercise 9.23 Let <span class="math inline">\(T\)</span> be a test statistic such that under <span class="math inline">\(\mathbb{M}_{0}, T \underset{d}{\longrightarrow} \chi_{3}^{2}\)</span>. Since <span class="math inline">\(\mathbb{P}\left[\chi_{3}^{2}&gt;7.815\right]=0.05\)</span>, an asymptotic <span class="math inline">\(5 %\)</span> test of <span class="math inline">\(\mathbb{H}_{0}\)</span> rejects when <span class="math inline">\(T&gt;7.815\)</span>. An econometrician is interested in the Type I error of this test when <span class="math inline">\(n=100\)</span> and the data structure is well specified. She performs the following Monte Carlo experiment.</p>
<ul>
<li><p><span class="math inline">\(B=200\)</span> samples of size <span class="math inline">\(n=100\)</span> are generated from a distribution satisfying <span class="math inline">\(\mathbb{H}_{0}\)</span>.</p></li>
<li><p>On each sample, the test statistic <span class="math inline">\(T_{b}\)</span> is calculated.</p></li>
<li><p>She calculates <span class="math inline">\(\hat{p}=B^{-1} \sum_{b=1}^{B} \mathbb{1}\left\{T_{b}&gt;7.815\right\}=0.070\)</span>.</p></li>
<li><p>The econometrician concludes that the test <span class="math inline">\(T\)</span> is oversized in this context-it rejects too frequently under <span class="math inline">\(\mathbb{M}_{0}\)</span>.</p></li>
</ul>
<p>Is her conclusion correct, incorrect, or incomplete? Be specific in your answer.</p>
<p>Exercise 9.24 Do a Monte Carlo simulation. Take the model <span class="math inline">\(Y=\alpha+X \beta+e\)</span> with <span class="math inline">\(\mathbb{E}[X e]=0\)</span> where the parameter of interest is <span class="math inline">\(\theta=\exp (\beta)\)</span>. Your data generating process (DGP) for the simulation is: <span class="math inline">\(X\)</span> is <span class="math inline">\(U[0,1]\)</span>, <span class="math inline">\(e \sim \mathrm{N}(0,1)\)</span> is independent of <span class="math inline">\(X\)</span>, and <span class="math inline">\(n=50\)</span>. Set <span class="math inline">\(\alpha=0\)</span> and <span class="math inline">\(\beta=1\)</span>. Generate <span class="math inline">\(B=1000\)</span> independent samples with <span class="math inline">\(\alpha\)</span>. On each, estimate the regression by least squares, calculate the covariance matrix using a standard (heteroskedasticity-robust) formula, and similarly estimate <span class="math inline">\(\theta\)</span> and its standard error. For each replication, store <span class="math inline">\(\widehat{\beta}, \widehat{\theta}, T_{\beta}=(\widehat{\beta}-\beta) / s(\widehat{\beta})\)</span>, and <span class="math inline">\(T_{\theta}=(\widehat{\theta}-\theta) / s(\widehat{\theta})\)</span>.</p>
<ol type="a">
<li><p>Does the value of <span class="math inline">\(\alpha\)</span> matter? Explain why the described statistics are invariant to <span class="math inline">\(\alpha\)</span> and thus setting <span class="math inline">\(\alpha=0\)</span> is irrelevant.</p></li>
<li><p>From the 1000 replications estimate <span class="math inline">\(\mathbb{E}[\widehat{\beta}]\)</span> and <span class="math inline">\(\mathbb{E}[\widehat{\theta}]\)</span>. Discuss if you see evidence if either estimator is biased or unbiased.</p></li>
<li><p>From the 1000 replications estimate <span class="math inline">\(\mathbb{P}\left[T_{\beta}&gt;1.645\right]\)</span> and <span class="math inline">\(\mathbb{P}\left[T_{\theta}&gt;1.645\right]\)</span>. What does asymptotic theory predict these probabilities should be in large samples? What do your simulation results indicate?</p></li>
</ol>
<p>Exercise 9.25 The data set Invest1993 on the textbook website contains data on 1962 U.S. firms extracted from Compustat, assembled by Bronwyn Hall, and used in Hall and Hall (1993).</p>
<p>The variables we use in this exercise are in the table below. The flow variables are annual sums. The stock variables are beginning of year.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">year</th>
<th style="text-align: left;">year of the observation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(I\)</span></td>
<td style="text-align: left;">inva</td>
<td style="text-align: left;">Investment to Capital Ratio</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(Q\)</span></td>
<td style="text-align: left;">vala</td>
<td style="text-align: left;">Total Market Value to Asset Ratio (Tobin’s Q)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(C\)</span></td>
<td style="text-align: left;">cfa</td>
<td style="text-align: left;">Cash Flow to Asset Ratio</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(D\)</span></td>
<td style="text-align: left;">debta</td>
<td style="text-align: left;">Long Term Debt to Asset Ratio</td>
</tr>
</tbody>
</table>
<ol type="a">
<li><p>Extract the sub-sample of observations for 1987. There should be 1028 observations. Estimate a linear regression of <span class="math inline">\(I\)</span> (investment to capital ratio) on the other variables. Calculate appropriate standard errors.</p></li>
<li><p>Calculate asymptotic confidence intervals for the coefficients.</p></li>
<li><p>This regression is related to Tobin’s <span class="math inline">\(q\)</span> theory of investment, which suggests that investment should be predicted solely by <span class="math inline">\(Q\)</span> (Tobin’s <span class="math inline">\(Q\)</span> ). This theory predicts that the coefficient on <span class="math inline">\(Q\)</span> should be positive and the others should be zero. Test the joint hypothesis that the coefficients on cash flow <span class="math inline">\((C)\)</span> and debt <span class="math inline">\((D)\)</span> are zero. Test the hypothesis that the coefficient on <span class="math inline">\(Q\)</span> is zero. Are the results consistent with the predictions of the theory?</p></li>
<li><p>Now try a nonlinear (quadratic) specification. Regress <span class="math inline">\(I\)</span> on <span class="math inline">\(Q, C, D, Q^{2}, C^{2}, D^{2}, Q \times C, Q \times D, C \times D\)</span>. Test the joint hypothesis that the six interaction and quadratic coefficients are zero.</p></li>
</ol>
<p>Exercise 9.26 In a paper in 1963, Marc Nerlove analyzed a cost function for 145 American electric companies. Nerlov was interested in estimating a cost function: <span class="math inline">\(C=f(Q, P L, P F, P K)\)</span> where the variables are listed in the table below. His data set Nerlove1963 is on the textbook website.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">C</th>
<th style="text-align: left;">Total Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Q</td>
<td style="text-align: left;">Output</td>
</tr>
<tr class="even">
<td style="text-align: left;">PL</td>
<td style="text-align: left;">Unit price of labor</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PK</td>
<td style="text-align: left;">Unit price of capital</td>
</tr>
<tr class="even">
<td style="text-align: left;">PF</td>
<td style="text-align: left;">Unit price of fuel</td>
</tr>
</tbody>
</table>
<ol type="a">
<li>First, estimate an unrestricted Cobb-Douglass specification</li>
</ol>
<p><span class="math display">\[
\log C=\beta_{1}+\beta_{2} \log Q+\beta_{3} \log P L+\beta_{4} \log P K+\beta_{5} \log P F+e .
\]</span></p>
<p>Report parameter estimates and standard errors.</p>
<ol start="2" type="a">
<li><p>What is the economic meaning of the restriction <span class="math inline">\(\mathbb{H}_{0}: \beta_{3}+\beta_{4}+\beta_{5}=1\)</span> ?</p></li>
<li><p>Estimate (9.23) by constrained least squares imposing <span class="math inline">\(\beta_{3}+\beta_{4}+\beta_{5}=1\)</span>. Report your parameter estimates and standard errors.</p></li>
<li><p>Estimate (9.23) by efficient minimum distance imposing <span class="math inline">\(\beta_{3}+\beta_{4}+\beta_{5}=1\)</span>. Report your parameter estimates and standard errors.</p></li>
<li><p>Test <span class="math inline">\(\mathbb{H}_{0}: \beta_{3}+\beta_{4}+\beta_{5}=1\)</span> using a Wald statistic.</p></li>
<li><p>Test <span class="math inline">\(\mathbb{H}_{0}: \beta_{3}+\beta_{4}+\beta_{5}=1\)</span> using a minimum distance statistic. Exercise 9.27 In Section 8.12 we reported estimates from Mankiw, Romer and Weil (1992). We reported estimation both by unrestricted least squares and by constrained estimation, imposing the constraint that three coefficients ( <span class="math inline">\(2^{n d}, 3^{r d}\)</span> and <span class="math inline">\(4^{t h}\)</span> coefficients) sum to zero as implied by the Solow growth theory. Using the same dataset MRW1992 estimate the unrestricted model and test the hypothesis that the three coefficients sum to zero.</p></li>
</ol>
<p>Exercise 9.28 Using the cps09mar dataset and the subsample of non-Hispanic Black individuals (race code <span class="math inline">\(=2\)</span> ) test the hypothesis that marriage status does not affect mean wages.</p>
<ol type="a">
<li><p>Take the regression reported in Table 4.1. Which variables will need to be omitted to estimate a regression for this subsample?</p></li>
<li><p>Express the hypothesis “marriage status does not affect mean wages” as a restriction on the coefficients. How many restrictions is this?</p></li>
<li><p>Find the Wald (or F) statistic for this hypothesis. What is the appropriate distribution for the test statistic? Calculate the p-value of the test.</p></li>
<li><p>What do you conclude?</p></li>
</ol>
<p>Exercise 9.29 Using the cps09mar dataset and the subsample of non-Hispanic Black individuals (race code <span class="math inline">\(=2\)</span> ) and white individuals (race code <span class="math inline">\(=1\)</span> ) test the hypothesis that the returns to education is common across groups.</p>
<ol type="a">
<li><p>Allow the return to education to vary across the four groups (white male, white female, Black male, Black female) by interacting dummy variables with education. Estimate an appropriate version of the regression reported in Table 4.1.</p></li>
<li><p>Find the Wald (or F) statistic for this hypothessis. What is the appropriate distribution for the test statistic? Calculate the p-value of the test.</p></li>
<li><p>What do you conclude?</p></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chpt08-restricted-est.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Restricted Estimation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chpt10-resample-method.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Resampling Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
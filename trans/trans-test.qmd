---
title: "Untitled"
format: 
  html:
    self-contained: true
    self-contained-math: true
    
---


## 准备R包

```{r}
require(knitr)
require(tidyverse)
require(stringr)
require(purrr)
require(here)
#renv::install("ropensci/googleLanguageR")
require(googleLanguageR)

#renv::install("keyring")
library("keyring")
# the package is not on cran now
#renv::install("ChristopherLucas/translateR")
require("translateR")
#renv::install("textreadr")
require("textreadr")

```

## 准备测试文本

```{r}
file_path <- here("chpt02-ce.qmd")
tbl_tex <- readLines(file_path) %>%
  as_tibble() %>%
  rename("text" = "value") %>%
  add_column(row = 1:nrow(.), 
             .before = "text")

# tibble contains all contents
tbl_text <- tbl_tex %>%
  filter(text!="")

# string of vector
text_vector <- tbl_text %>%
  filter(str_detect(text, "An alternative notation which includes both discrete and continuous")) %>%
  pull(text)

# string of data frame
text_dt <- tbl_text %>%
  .[178:181,]

```


## 方法1：translateR::translate

### 设置翻译接口

google clound平台的相关准备工作。

- `id`为project id（项目 ID）。

- `token`为API密钥：my project $\Rightarrow$ API和服务 $\Rightarrow$ 凭据 $\Rightarrow$ API密钥 $\Rightarrow$ 显示密钥

```{r, eval=FALSE}
# this will run only once
# make secretes
keyring::keyring_create("gg-translation2022")
keyring::key_set("token", keyring = "gg-translation2022")

### donot forget to lock the keyring after use
keyring::keyring_lock("gg-translation22")

# make secretes
keyring::keyring_create("ms-translation22")
keyring::key_set("id", keyring = "ms-translation22")
keyring::key_set("secret", keyring = "ms-translation22")
### donot forget to lock the keyring after use
keyring::keyring_lock("ms-translation22")
```

### 文本翻译：dataframe

```{r, eval=FALSE, echo=TRUE}
# translate the data frame
result <- translateR::translate(
  dataset = text_dt, 
  content.field = "text",
  google.api.key = list(
    key=keyring::key_get(
      "token", 
      keyring = "gg-translation2022")
    ),
  source.lang = "en",
  target.lang = "zh-CN") 

file_path <- here("data/ggtrans/trans2dt.rds")
write_rds(result, file_path)
```

```{r, echo=TRUE}
file_path <- here("data/ggtrans/trans2dt.rds")
string_dt <- read_rds(file_path)

kable(string_dt)
```


### 文本翻译：vector

```{r, eval=FALSE, echo=TRUE}
# translate the data frame
result <- translateR::translate(
  content.vec = text_dt$text, 
  google.api.key = list(
    key=keyring::key_get(
      "token", 
      keyring = "gg-translation2022")
    ),
  source.lang = "en",
  target.lang = "zh-CN") 


file_path <- here("data/ggtrans/trans2vec.rds")
write_rds(result, file_path)
```

```{r, echo=TRUE}
file_path <- here("data/ggtrans/trans2vec.rds")
string_vec <- read_rds(file_path)

string_vec
```


## 方法2：googleLanguageR

```{r, eval=FALSE, echo=TRUE}
# translate with google translate API
#renv::install("ropensci/googleLanguageR")
#gl_auth("C:/Users/huhua/json/googleLanguageR.json")
library(googleLanguageR)
gl_auth("C:/Users/huhua/json/googleLanguageR.json")

result <- gl_translate(
  t_string = text_vector, 
  target = "zh-CN")$translatedText

file_path <- here("data/ggtrans/trans2vec_open.rds")
write_rds(result, file_path)
```

```{r, echo=TRUE}
file_path <- here("data/ggtrans/trans2vec_open.rds")
string_vec <- read_rds(file_path)

string_vec
```


## 处理公式环境（双美元符号对）

```{r}
tbl_dollar <- tbl_tex %>%
  mutate(
    double_dollar = str_detect(text, "^\\$\\$$"),
    index_raw = row_number(row),
    index_detect = ifelse(
      double_dollar==TRUE, 
      index_raw,NA)
    ) 

  # identify position
  lines <- tbl_dollar %>% 
    filter(!is.na(index_detect)) %>%
    pull(index_detect)
  
  # assumes existing perfect paired double dollar symbols
  row_tar <- seq_len(length(lines))%%2  # row indicator
  lines_star <- lines[row_tar==1]   # start row (odd)
  lines_end <- lines[row_tar==0]   # end row (enven)
  
  lines_tar <- NULL
  for (i in 1:length(lines_star)){
    lines_tem <- lines_star[i]:lines_end[i]
    lines_tar <- c(lines_tar, lines_tem)
  }
  
  # tag it 
  tbl_work <- tbl_dollar  %>%
    # tag lines within double dollar pairs
    mutate(
      dollars = ifelse(
        index_raw %in% lines_tar, 
        TRUE, FALSE)
      ) %>%
    mutate(
      tabs = str_detect(text, "^\\|.*?\\|$")) %>%
    # tag lines of markdown image
    mutate(
      img = str_detect(text, "^\\!\\[\\]\\(images")
      ) %>%
    # tag empty lines
    mutate(
      empty = ifelse(text=="", TRUE, FALSE)
    ) %>%
    # tag lines need to translate
    mutate(
      gotrans = ifelse(
        dollars+tabs+img+empty==0,
        TRUE, FALSE)
    ) %>%
    # tag heading
    mutate(heading = str_extract(text, "^#{1,3}"),
           text_nohash = str_replace_all(text, "(^#{1,3})", ""))
```


## (辅助函数)翻译段落

```{r}
#' Translate paragraph contains math symbol whin sigle dollar symbol pairs.
#'
#' @param text character. Target character paragraph.
#' @param auth character. File path of googleLanguageR API authorized json file
#'
#' @return
#' @export
#'
#' @examples
#' math_complex <- tbl_text$text[117]
#' auth_json <- "C:/Users/huhua/json/googleLanguageR.json"
#' 
#' transed_math <- trans_mathParagraph(
#'   text = math_complex, 
#'   auth = auth_json) 

trans_mathParagraph <- function(text, auth) {
  # prepare
  library(googleLanguageR)
  gl_auth(auth)
  
  # split paragraph
  split_raw <- strsplit(text,
              split = "(?=[\\$])",
              perl = TRUE) %>% 
    unlist()
  lines <- grep("\\$", split_raw)
  
  split_handle <- split_raw
  
  # identify position
  row_tar <- seq_len(length(lines))%%2  # row indicator
  lines_star <- lines[row_tar==1]   # start row (odd)
  lines_end <- lines[row_tar==0]   # end row (enven)
  
  # loop substitute 
  # i <- 1
  lines_math <- NULL
  lines_handle <- NULL
  for (i in 1:length(lines_star)){
    # text of raw math
    lines_math[i] <- split_handle[lines_star[i]+1]
    # replace 
    lines_eq <- paste0("matheq", i)
    split_handle[lines_star[i]+1] <- lines_eq
    # text of handle math
    lines_handle[i] <- lines_eq
  }
   
  # now translate it
  paragraph_handle <- paste0(split_handle, collapse = "")
  trans_result <- googleLanguageR::gl_translate(
    t_string = paragraph_handle, 
    target = "zh-CN")$translatedText
  Sys.sleep(0.2)
  
  # then re-split the paragraph
  split_trans <- strsplit(trans_result,
              split = "(?=[\\$])",
              perl = TRUE) %>% 
    unlist()
  
  # match math after translation
  ## note: math eq order may not be the same sequence as it before.
  
  ## here is the math pairs
  tbl_math <- tibble(
    math_raw = lines_math,
    math_handle = lines_handle)
  
  ## now match and replace
  tbl_result <- tibble(chn = split_trans) %>%
    left_join(., tbl_math, 
              by = c("chn"="math_handle")) %>%
    mutate(
      chn_final = ifelse(
        str_detect(chn, "^matheq\\d{1,2}"),
        math_raw, chn))
  
  paragraph_final <- paste0(tbl_result$chn_final, collapse = "")
  return(paragraph_final)
}

```

## 翻译公式段落

```{r}
n_pars <- sum(tbl_work$gotrans)
auth_json <- "C:/Users/huhua/json/googleLanguageR.json"

## !important! run only once!
## google translate will chage your fees!!
tbl_trans <- tbl_work %>%
  #head(100) %>%
  mutate(
    chn = map2(
      .x = text_nohash, .y = gotrans,
      .f = function(x,y){
        if(y==TRUE) {
          out <- trans_mathParagraph(
            text = x,
            auth = auth_json)
          } else{
          out <- ""
          }
      return(out)
      }
      )
    )

# now tidy the result
tbl_tidy <- tbl_trans %>%
  mutate( # add hashed chn
    text_tidy = ifelse(
      str_detect(heading,"^#{1,3}"),
      str_c(heading, chn, sep = " "),
      chn)
    ) %>%
  mutate( # add other chn
    text_tidy = ifelse(
      is.na(text_tidy),
      chn, text_tidy
      )
  ) %>%
  mutate(     # fill other lines
    text_tidy = ifelse(
      text_tidy=="",
      text, text_tidy
      )
  )

```

## 导出为qmd文件（翻译后）

```{r}
file_base <- basename(path = file_path)
file_out <- here(
  paste0(
    "trans/",
    str_replace(file_base, "\\.qmd$","-chn\\.qmd")
    )
  )
# write out all modified text
writeLines(unlist(tbl_tidy$text_tidy), file_out)
  
```


## 导出翻译后的表格

考虑到google translation API 需要收费。


```{r}
file_base <- basename(path = file_path)
file_out <- here(
  paste0(
    "trans/",
    str_replace(file_base, "\\.qmd$","-chn\\.rds")
    )
  )

# write table
write_rds(tbl_tidy, file_out)
```


